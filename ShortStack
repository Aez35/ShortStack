#!/usr/bin/perl -w
# See below the __END__ mark for docmentation, license, citation, etc., or just see the README distributed with this script

use Getopt::Long;
use strict;

###############MAIN PROGRAM BLOCK
##### VERSION
my $version_num = "2.0.1";

##### get options and validate them

# usage statement and option gathering
my $usage = usage($version_num);

# If user has no arguments, give help statement and quit
unless($ARGV[0]) {
    die "\n$usage\n";
}

# Initial option definition, inlcuding default settings
my $outdir = '';
my $mindepth = 20;
my $pad = 100;
my $dicermin = 20;
my $dicermax = 24;
my $minstrandfrac = 0.8;
my $mindicerfrac = 0.8;  ## lowered to 0.8 from 0.85 as of 0.4.0
my $count = '';
my $nohp = 0;
my $phasesize = 21;
my $flag_file = "NULL";
my $miRType = "plant";  ## parameter added as of version 0.3.0

## New in 1.0.0
my $adapter;  ## as of version 2.0.0, this is also used for butter
my $help;
my $version;
my $bamfile;
my $align_only;

## New in 1.1.0
my $read_group;

## New in 1.2.1 .. multicore usage during bowtie alignment
my $bowtie_cores = 1;  ## default is 1 ... this is for butter's --aln_cores option

## New in 2.0.0
my $reads;
my $no_condense; ## for butter
my $mismatches; ## for butter
my $max_rep; ## for butter
my $ranmax; ## for butter
my $HPscore = 0.8; ## minimum maple score for a FAIL locus required to keep as a potential HP-derived cluster.

# get user options from command line
GetOptions ('outdir=s' => \$outdir,
	    'mindepth=i' => \$mindepth,
	    'pad=i' => \$pad,
	    'dicermin=i' => \$dicermin,
	    'dicermax=i' => \$dicermax,
	    'minstrandfrac=f' => \$minstrandfrac,
	    'mindicerfrac=f' => \$mindicerfrac,
	    'count=s' => \$count,
	    'nohp' => \$nohp,
	    'phasesize=s' => \$phasesize,
	    'flag_file=s' => \$flag_file,
	    'miRType=s' => \$miRType,
	    'adapter=s' => \$adapter,
	    'bamfile=s' => \$bamfile,
	    'align_only' => \$align_only,
	    'read_group=s' => \$read_group,
	    'bowtie_cores=i' => \$bowtie_cores,
	    'reads=s' => \$reads,
	    'no_condense' => \$no_condense,
	    'mismatches=i' => \$mismatches,
	    'max_rep=i' => \$max_rep,
	    'ranmax=i' => \$ranmax,
	    'HPscore=f' => \$HPscore,
	    'version' => \$version,
	    'help' => \$help);

# If help, print and quit
if($help) {
    my $long_help = full_help($version_num);
    die "\n$long_help\n";
}

# If version, print version and quit
if($version) {
    die "ShortStack version $version_num\n";
}

# default output directory is ShortStack_[time], where time is the number of non-leap seconds since 00:00:00 UCT Jan 1, 1970
unless($outdir) {
    my $time = time;
    $outdir = "ShortStack" . "_$time";
}
# ensure the output directory does not already exist.  If it does, quit and complain
# then create it or die tryin'
if(-d $outdir) {
    die "FATAL: Output directory $outdir already exists\n$usage\n";
} else {
    system "mkdir $outdir";
}

#designate a log file
our $logfile = "$outdir" . "\/" . "Log\.txt";

# Determine the mode
my $mode;
# Mode 1: Trim, align, then analyze.
# Expect both reads and adapter.  bamfile is irrelevant.
if(($reads) and ($adapter)) {
    # Should be mode 1. Ensure adapter specified and valid .. must be 8nts, ATCG
    ## Adapters can now be comma-delimited
    my $adapter_check = check_adapter($adapter);
    unless($adapter_check) {
	log_it($logfile,"FATAL: Option --adapter must be a string of at least 8 ATGC characters .. case-insensitive or comma delimited set of such\n\n$usage\n");
	exit;
    }
    $mode = 1;
    
    # if bamfile, warn that it is an irrelevant option
    if($bamfile) {
	log_it($logfile,"\nWARNING: in mode 1 option --bamfile is irrelevant. It is being ignored\n");
    }
} elsif ($reads) {
    # Should be mode 2.  ... align, assume the reads are all trimmed
    $mode = 2;

    # if bamfile, warn that it is an irrelevant option
    if($bamfile) {
	log_it($logfile,"\nWARNING: in mode 2 option --bamfile is irellevant. It is being ignored\n");
    }
} elsif ($bamfile) {
    # mode 3. 
    $mode = 3;

    # Warn about irrelevant option --adapter
    if($adapter) {
	log_it($logfile,"\nWARNING: in mode 3 option --adapter is irrelevant. It is being ignored\n");
    }
} else {
    log_it($logfile,"\nFATAL: Could not determine mode, aborting\n");
    exit;
}

## Check dependencies

# samtools
my $to_check = "samtools";
my $samtools_check = install_check($to_check);
unless($samtools_check) {
    log_it($logfile, "\nFATAL: samtools not found\n\n");
    exit;
}

# maple
$to_check = "maple";
my $maple_check = install_check($to_check);
unless($maple_check) {
    log_it($logfile, "\nFATAL: maple not found\n\n");
    exit;
}

## make sure maple's unique dependencies are there too .. RNAfold and RNAplot
$to_check = "RNAfold";
my $RNAfold_check = install_check($to_check);
unless($RNAfold_check) {
    log_it($logfile, "\nFATAL: RNAfold not found\n\n");
    exit;
}

$to_check = "RNAplot";
my $RNAplot_check = install_check($to_check);
unless($RNAplot_check) {
    log_it($logfile, "\nFATAL: RNAplot not found\n\n");
    exit;
}

# check for bowtie and butter if modes 1 or 2
# also check for butter

if(($mode == 1) or ($mode == 2)) {
    $to_check = "bowtie";
    my $bowtie_check = install_check($to_check);
    unless($bowtie_check) {
	log_it($logfile, "\nFATAL: bowtie not found\n\n");
	exit;
    }
    $to_check = "bowtie-build";
    my $bowtie_build_check = install_check($to_check);
    unless($bowtie_build_check) {
	log_it($logfile, "\nFATAL: bowtie-build not found\n\n");
	exit;
    }
    $to_check = "butter";
    my $butter_check = install_check($to_check);
    unless($butter_check) {
	log_it($logfile, "\nFATAL: butter not found\n\n");
	exit;
    }
}

# Validate the options

unless(($mindepth > 0) and
       ($mindepth < 1000000)) {
    log_it($logfile,"FATAL: mindepth must be more than zero and less than one million\n\n$usage\n");
    exit;
}

# ensure that option --pad is present and logical -- 0 >= x < 100,000
unless(($pad >= 0) and ($pad <= 100000)) {
    log_it($logfile,"FATAL: Option --pad must be a number greater than or equal to zero and less than one hundred thousand\n\n$usage\n");
    exit;
}

# ensure that option --dicermin is present and logical -- 15 >= x <= 35, and less than or equal to dicermax
unless(($dicermin >= 15) and ($dicermin <= 35) and ($dicermin <= $dicermax)) {
    log_it($logfile, "FATAL: Option --dicermin must be a number between 15 and 35, and less than or equal to option --dicermax\n\n$usage\n");
    exit;
}

# ensure that option --dicermax is present and logical -- 15 >= x <= 35, and more than or equal to dicermin
unless(($dicermax >= 15) and ($dicermax <= 35) and ($dicermin <= $dicermax)) {
    log_it($logfile,"FATAL: Option --dicermax must be a number between 15 and 35, and more than or equal to option --dicermin\n\n$usage\n");
    exit;
}

# ensure that option --minstrandfrac is present and logical -- 0.5 >= x <= 1
unless(($minstrandfrac >= 0.5) and ($minstrandfrac <= 1)) {
    log_it($logfile, "FATAL: Option --minstrandfrac must be number greater than or equal to 0.5 and less than or equal to one\n\n$usage\n");
    exit;
}

# ensure that option --mindicerfrac is present and logical -- 0 >= x <= 1
unless(($mindicerfrac >= 0) and ($mindicerfrac <= 1)) {
    log_it($logfile, "FATAL: Option -mindicerfrac must be number greater than or equal to 0 and less than or equal to one\n$usage\n");
    exit;
}

# if the --count option was provided, make sure the indicated file can be read
if($count) {
    unless(-r $count) {
	log_it($logfile, "FATAL: Option --count : File $count could not be read\n\n$usage\n");
	exit;
    }
    # As of version 0.3.0, count mode also forces nohp mode
    $nohp = 1;
}

# check the --phasesize option to see if it is a number between --dicermin and --dicermax, OR 'all', OR 'none'
if($phasesize =~ /^\d+$/) {
    unless(($phasesize >= $dicermin) and
	   ($phasesize <= $dicermax)) {
	log_it($logfile, "FATAL: Option --phasesize must be an integer within the --dicermin to --dicermax size range OR \'all\'\n\n$usage\n");
	exit;
    }
} else {
    unless(($phasesize eq "all") or
	   ($phasesize eq "none")) {
	log_it($logfile, "FATAL: Option --phasesize must be an integer within the --dicermin to --dicermax size range OR \'all\' OR \'none\'\n\n$usage\n");
	exit;
    }
}

# parse the mirType and the associated settings
unless(($miRType eq "plant") or ($miRType eq "animal")) {
    log_it($logfile, "FATAL: Option --miRType $miRType is invalid\.  Must be either \'plant\' , \'animal\', or unspecified \(unspecified defaults to \'plant\'\)\n\n$usage\n");
    exit;
}

## Check the option bowtie_cores .. integer of 1 or more
if($bowtie_cores =~ /^\d+$/) {
    unless($bowtie_cores >= 1) {
	log_it($logfile, "\nFATAL: Option --bowtie_cores must be an integer of 1 or more\n");
	exit;
    }
} else {
	log_it($logfile, "\nFATAL: Option --bowtie_cores must be an integer of 1 or more\n");
	exit;
}

## options mismatches, max_rep, and ranmax will be validated by butter. If they're empty, butter just uses it's defaults.

## check option HPscore
unless(($HPscore >= 0) and ($HPscore <= 1)) {
    log_it($logfile, "\nFATAL: Option --HPscore must be a value between 0 and 1\n");
    exit;
}

###############
# check that the genome file is at the end of @ARGV
my $genome = pop @ARGV;
unless(-r $genome) {
    log_it($logfile, "FATAL: genome file $genome is not readable\n\nFATAL\n$usage\n");
    exit;
}

#### 
# See if the user provided a flag_file, and if so, make sure it is readable
if($flag_file ne "NULL") {
    unless(-r $flag_file) {
	log_it($logfile, "FATAL: The provided flag file $flag_file from user option --flag_file could not be read\n$usage\n");
	exit;
    }
}
##

##### Report to user on initialization of the run
log_it ($logfile,"\nShortStack $version_num\n");
log_it ($logfile,`date`);
log_it ($logfile,"Genome: $genome\n");
log_it ($logfile,"Output Directory: $outdir\n");
log_it($logfile,"Pre-analysis mode: $mode ");
if($mode == 1) {
    log_it($logfile,": Trim reads, then align trimmed reads, \n\tUntrimmed Reads: $reads\n");
    log_it($logfile, "\tAdapter: $adapter\n");
} elsif ($mode == 2) {
    log_it($logfile,"Align pre-trimmed reads\n\tTrimmed Reads: $reads\n");
} elsif ($mode == 3) {
    log_it($logfile,"Analyze pre-existing BAM alignment\n\tAlignments: $bamfile\n");
    if($align_only) {
	log_it($logfile,"\nWARNING: option --align_only is irrelevant if you provide a bamfile. It is being ignored and a full analysis is proceeding\n");
    }
}

if($align_only) {
    log_it($logfile, "\nAlign-only mode: Trimmed reads will be aligned but no analysis will be performed.\n");
} else {
    log_it($logfile, "Read Group: ");
    if($read_group) {
	log_it($logfile, "$read_group\n");
    } else {
	log_it($logfile, "None .. all reads will be analyzed.\n");
    }
    log_it ($logfile,"Flag file of loci to report if overlapped: ");
    if($flag_file ne "NULL") {
	log_it ($logfile,"$flag_file\n");
    } else {
	log_it ($logfile,"Not Provided\n");
    }
    
    log_it ($logfile,"Clusters:");
    if($count) {
	log_it ($logfile," Running in \"count\" mode\. User provided clusters from file $count\n");
    } else {
	log_it ($logfile," To be calculated de novo\n");
	log_it ($logfile,"Island threshold: $mindepth mappings\n");
	log_it ($logfile,"Padding around initial islands: $pad nts\n");
    }
    log_it ($logfile,"Dicer size range: $dicermin to $dicermax\n");
    if($nohp) {
	log_it ($logfile,"Running in \"nohp\" mode: Hairpins and MIRNAs will not be inferred\n");
    } else {
	log_it ($logfile,"microRNA type: $miRType\n");
	log_it ($logfile,"Minimum maple score to keep failed MIRNA as a HP locus: $HPscore\n");
    }
    log_it ($logfile,"Minimum fraction of mappings to assign a polarity to a non-hairpin cluster: $minstrandfrac\n");
    log_it ($logfile,"Minimum fraction of mappings within the Dicer size range to annotate a locus as Dicer-derived: $mindicerfrac\n");
    log_it ($logfile,"Cluster type to analyze for phasing: $phasesize\n");
}

# Next, check for the presence of .fai index file corresponding to the genome.  If not found, create one with samtools
my $expected_faidx = "$genome" . "\.fai";
unless(-e $expected_faidx) {
    log_it ($logfile,"Expected genome index $expected_faidx for genome file $genome not found\.  Creating it using samtools faidx");
    system "samtools faidx $genome";
log_it ($logfile," done\n\n");
}


##############################################
# butter

if(($mode == 1) or ($mode == 2)) {
    my @input_read_files = split (",", $reads);
    my $butter_call = "butter --aln_cores $bowtie_cores";
    if($no_condense) {
	$butter_call .= " --no_condense";
    }
    if($adapter) {
	$butter_call .= " --adapter $adapter";
    }
    if($mismatches) {
	$butter_call .= " --mismatches $mismatches";
    }
    if($max_rep) {
	$butter_call .= " --max_rep $max_rep";
    }
    if($ranmax) {
	$butter_call .= " --ranmax $ranmax";
    }
    my @output_bams = ();
    foreach my $irf (@input_read_files) {
	$butter_call .= " $irf $genome";
	
	system "$butter_call";
	my $outbam = $irf;
	$outbam =~ s/\.[^\.]+$/\.bam/;
	# verify
	unless(-r $outbam) {
	    die "\nFATAL in ShortStack: failed to find expected bam file $outbam\n";
	}
	push(@output_bams,$outbam);
    }
    
    # If more than one, merge em
    if((scalar @output_bams) > 1) {
	$bamfile = merge_em(\@output_bams,\$outdir);
    } else {
	$bamfile = $output_bams[0];
    }
    
    if($align_only) {
	log_it($logfile,"\nRun was in --align_only mode .. terminating.\n");
	exit;
    }
}

################################################
# bam file validation
my %rgs = validate_bam($bamfile,$expected_faidx);
if(exists($rgs{'BAD'})) {
    log_it($logfile,"\nBAM file validation failed. Aborting run.\n");
    exit;
}

################################################
# If user wanted to only analyze a specific read-group, ensure it is in the bamfile
# Clear hash if it had a null place-holder
if(exists($rgs{'NULL'})) {
    %rgs = ();
}
if($read_group) {
    unless(exists($rgs{$read_group})) {
	log_it($logfile, "\nFATAL: Read group $read_group specified with option --read_group is NOT present in the bamfile\!\n");
	exit;
    }
}

###############################################

##### Phase One: Identify Clusters
my %names = ();  ## keys = locusIDs (e.g. Chr1:1-1000) , values = name designations

log_it ($logfile, "\n");
log_it ($logfile,`date`);
log_it ($logfile,"Phase One: Identifying Clusters");
my @clusters = ();
if($count) {
    log_it ($logfile," a priori from file $count\n");
    @clusters = get_clusters_a_priori($count);
    %names = get_names_countmode($count);  ## if names not present in count file, arbitrary names assigned
} else {
    log_it ($logfile," de novo\n");

    my @islands = get_islands($bamfile,$mindepth,$expected_faidx,$read_group);
    
    @clusters = merge_clusters(\@islands,\$pad,\$genome);
    
    %names = get_names_simple(\@clusters);
}

my $phase_one_n_clusters;
if(@clusters) {
    $phase_one_n_clusters = scalar @clusters;
    log_it ($logfile,"Phase One complete: Found $phase_one_n_clusters Clusters\n\n");
} else {
    log_it ($logfile,"Sorry, no clusters meeting your criteria were found in these data\.\n");
    exit;
}

### NEW PHASE 2 -- INITIAL QUANTIFICATION

log_it ($logfile,`date`);
log_it ($logfile,"Phase Two: Quantify all clusters\n");

my %quant_master = quant(\@clusters,\$bamfile,\$dicermin,\$dicermax,\$minstrandfrac,\$mindicerfrac,\$phasesize,\%names, \$read_group);

# in this initial hash, the fields are
#[0] : locus
#[1] : name
#[2] : size
#[3] : strand  (+ or -)
#[4] : frac_Watson
#[5] : total
#[6] : unique
#[7] : dicer_call
#[8] : phase_offset
#[9] : phase_pval
#[10] : short
#[11] : long
#[12 -- end] : dicer size mappings


# later, we will modify the notations for hairpins

# new fields to add
#[0] : locus
#[1] : name
#[2] : size
#[3] : MIRNA  <<<<<  MIRNA, HP, or .
#[4] : MIRNA_Score  <<<< some number, or NA
#[5] : strand
#[6] : frac_Watson
#[7] : total
#[8] : unique
#[9] : dicer_call
#[10] : phase_offset
#[11] : phase_pval
#[12] : short
#[13] : long
#[14--end] : dicer size mappings

my @final_clusters = ();

## Deal with MIRNA analysis now
if($nohp) {
    log_it ($logfile,"\n");
    log_it ($logfile,`date`);
    log_it ($logfile,"Running in nohp mode: Skipping phase three\n");
    @final_clusters = @clusters;
    # add extra fields to quant entries
    foreach my $fc (@final_clusters) {
	my @qf = split ("\t", $quant_master{$fc});
	$quant_master{$fc} = "$qf[0]\t$qf[1]\t$qf[2]\t\.\tNA";
	for (my $xxx = 3; $xxx < (scalar @qf); ++$xxx) {
	    $quant_master{$fc} .= "\t$qf[$xxx]";
	}
    }
} else {
    log_it ($logfile,"\n");
    log_it ($logfile,`date`);
    log_it ($logfile,"Phase Three: MIRNA discovery using maple\n");

    my $clusters_done = 0; ## for progress report in phase three
    log_it ($logfile,"\tProgress \(dots equal 5 percent\): ");
    my $dots_printed = 0;
    my $should_be_printed;
    
    # counters
    my $n_MIRNA = 0;
    my $n_FAIL_HP = 0;
    my $n_FAIL = 0;
    my $n_NA = 0;
    
    # hash the chromosome sizes from the .fai file
    open(FAI, "$expected_faidx");
    my %fai_hash = ();
    while (<FAI>) {
	chomp;
	my @fai_f = split ("\t", $_);
	$fai_hash{$fai_f[0]} = $fai_f[1];
    }
    close FAI;

    # to be analyzed by maple, clusters need a DicerCall of not N, a strand of - or +, and a size no more than 1000 nts
    my $m_strand;
    my $o_cluster_size;
    my $o_start;
    my $o_stop;
    my $adj_start;
    my $adj_stop;
    my $o_chr;
    my $delta;
    my $maple_outfile;
    
    # create and note directories for successful MIRNAs and near-MIRNAs
    my $MIR_dir = "$outdir" . "\/" . "MIRNAs";
    my $HP_dir = "$outdir" . "\/" . "HPs";
    system "mkdir $MIR_dir";
    system "mkdir $HP_dir";
    
    foreach my $original_cluster (@clusters) {
	if($original_cluster =~ /^(\S+):(\d+)-(\d+)$/) {
	    $o_cluster_size = $3 - $2 + 1;
	    $o_chr = $1;
	    $o_start = $2;
	    $o_stop = $3;
	} else {
	    die "FATAL: failed to parse cluster name $original_cluster in main at phase three\n";
	}
	my @qfields = split ("\t", $quant_master{$original_cluster});
	if ((($qfields[3] eq "+") or ($qfields[3] eq "-")) and
	    ($qfields[7] ne "N") and
	    ($o_cluster_size <= (1000-20-20))) {  ## all queries get at least 20nts padding on both sides
	    
	    if($qfields[3] eq "+") {
		$m_strand = "plus";
	    } elsif ($qfields[3] eq "-") {
		$m_strand = "minus";
	    }
	    
	    # adjust and filter based on size
	    # for miRType plant, all queries to maple must be at least 250 nts
	    if($miRType eq "plant") {
		if($o_cluster_size < 250) {
		    $delta = int (0.5 * (250 - $o_cluster_size));
		    $adj_start = $o_start - $delta;
		    $adj_stop = $o_stop + $delta;
		} else {
		    # pad by 20nts on either side
		    $adj_start = $o_start - 20;
		    $adj_stop = $o_stop + 20;
		}
	    } elsif ($miRType eq "animal") {
		# for miRType animal, queries should be expanded to 150 nts, and no more than 250 nts.
		if($o_cluster_size < 150) {
		    $delta = int (0.5 * (150 - $o_cluster_size));
		    $adj_start = $o_start - $delta;
		    $adj_stop = $o_stop + $delta;
		} else {
		    # pad by 20nts on either side
		    $adj_start = $o_start - 20;
		    $adj_stop = $o_stop + 20;
		}
	    # failsafes for edges of chromosomes
	    }
	    if($adj_start < 1) {
		$adj_start = 1;
	    }
	    if($adj_stop > $fai_hash{$o_chr}) {
		$adj_stop = $fai_hash{$o_chr};
	    }
	    
	    # final size failsafes
	    if((($miRType eq "plant") and (($adj_stop - $adj_start + 1) <= 1000)) or
	       (($miRType eq "animal") and (($adj_stop - $adj_start + 1) <= 250))) {
		
		# prepare, and the send it to maple
		my $maple_coordinates = "$o_chr" . ":" . "$adj_start" . "-" . "$adj_stop";
		my $output_coordinates;
		my $locus_score;
		my $locus_verdict;
		my $ps_file;
		my $maple_output;
		open(MAPLE, "maple --miRType $miRType --locus_name $names{$original_cluster} $bamfile $genome $maple_coordinates $m_strand |");
		# parse the output stream and hold it temporarily
		while (<MAPLE>) {
		    $maple_output .= $_;
		    chomp;
		    ## lines to parse (examples)
		    ## Best Structure at Location scaffold_12:1858517-1858631 strand -
		    ## Locus verdict: PASS
		    ## Locus score: 0.992
		    ## Annotated post-script file: UserLocus.ps
		    if($_ =~ /Best Structure at Location (\S+)/) {
			$output_coordinates = $1;
		    }
		    if($_ =~ /Locus verdict: (\S+)/) {
			$locus_verdict = $1;
		    }
		    if($_ =~ /Locus score: (\S+)/) {
			$locus_score = $1;
		    }
		    if($_ =~ /Annotated post-script file: (\S+)/) {
			$ps_file = $1;
		    }
		}
		close MAPLE;
		
		# to avoid reporting NA, all four expected outputs must have been found
		if(($output_coordinates) and ($locus_verdict) and ($locus_score) and ($ps_file)) {
		    
		    # verdict and score will surely be reported. But should we keep the new coordinates and the maple output?
		    # That depends on the verdict, and the cutoff.
		    if(($locus_verdict eq "PASS") or
		       ($locus_score >= $HPscore)) {
			
			# keep the locus as a MIRNA or HP, adjust the coordinates, and re-write the master data accordingly
			# first, write outputs
			if($locus_verdict eq "PASS") {
			    system "mv $ps_file $MIR_dir\/";
			    $maple_outfile = "$MIR_dir" . "\/" . "$names{$original_cluster}" . ".txt";
			    open(MOUT, ">$maple_outfile");
			    print MOUT "$maple_output\n";
			    close MOUT;
			    ++$n_MIRNA;
			} elsif ($locus_verdict eq "FAIL") {
			    system "mv $ps_file $HP_dir\/";
			    $maple_outfile = "$HP_dir" . "\/" . "$names{$original_cluster}" . ".txt";
			    open(MOUT, ">$maple_outfile");
			    print MOUT "$maple_output\n";
			    close MOUT;
			    ++$n_FAIL_HP;
			}
			# re-quant
			my $requant_string = requant($quant_master{$original_cluster},$bamfile,$dicermin,$dicermax,$minstrandfrac,$mindicerfrac,$phasesize,$read_group,$locus_verdict,$locus_score,$output_coordinates);
			$quant_master{$output_coordinates} = $requant_string;
			delete $quant_master{$original_cluster};
			push(@final_clusters,$output_coordinates);
			
			
		    } else {
			# Keep original coordinates, don't output the maple output. Record maple verdict and score.
			system "rm -f $ps_file";
			push(@final_clusters,$original_cluster);
			my $newstring = "$qfields[0]\t$qfields[1]\t$qfields[2]\t\.\t$locus_score";
			for (my $ii = 3; $ii < (scalar @qfields); ++$ii) {
			    $newstring .= "\t$qfields[$ii]";
			}
			$quant_master{$original_cluster} = $newstring;
			++$n_FAIL;
		    }
		} else {
		    # no maple output or output incomplete (e.g., a failed or no structure, for instance). Keep original coordinates, report score as 0
		    if($ps_file) {
			system "rm -f $ps_file";
		    }
		    push(@final_clusters,$original_cluster);
		    my $newstring = "$qfields[0]\t$qfields[1]\t$qfields[2]\t\.\t0";
		    for (my $ii = 3; $ii < (scalar @qfields); ++$ii) {
			    $newstring .= "\t$qfields[$ii]";
			}
		    $quant_master{$original_cluster} = $newstring;
		    ++$n_NA;
		}
	    } else {
		# no maple analysis attempted. Keep original coordinates, report score as NA
		push(@final_clusters,$original_cluster);
		my $newstring = "$qfields[0]\t$qfields[1]\t$qfields[2]\t\.\tNA";
		for (my $ii = 3; $ii < (scalar @qfields); ++$ii) {
		    $newstring .= "\t$qfields[$ii]";
		}
		$quant_master{$original_cluster} = $newstring;
		++$n_NA;
	    }
	} else {
	    # no maple analysis attempted. Keep original coordinates, report score as NA
	    push(@final_clusters,$original_cluster);
	    my $newstring = "$qfields[0]\t$qfields[1]\t$qfields[2]\t\.\tNA";
	    for (my $ii = 3; $ii < (scalar @qfields); ++$ii) {
		$newstring .= "\t$qfields[$ii]";
	    }
	    $quant_master{$original_cluster} = $newstring;
	    ++$n_NA;
	}
	## progress
	++$clusters_done;
	$should_be_printed = int(($clusters_done / (scalar @clusters)) / 0.05);
	until($dots_printed == $should_be_printed) {
	    print ".";
	    ++$dots_printed;
	}
    }
    ## completion
    print " Done\n";
    print "\tMIRNAs: $n_MIRNA\n";
    print "\tHPs: $n_FAIL_HP\n";
    my $others = $n_NA + $n_FAIL;
    print "\tOthers: $others\n";
}


## Phase 4 - Final output
log_it($logfile,"\n");
log_it($logfile,`date`);
log_it($logfile,"Phase Four: Finalizing results and writing files\n");

unless($flag_file eq "NULL") {
    log_it ($logfile,"\tAssessing overlap of small RNA loci with loci from flag file $flag_file\n");
}

flag_overlap(\%quant_master, \$flag_file);

## after this conversion, a new column is inserted.  Now the fields are:
#[0] : locus
#[1] : name
#[2] : overlap <<<<<
#[3] : size
#[4] : MIRNA
#[5] : MIRNA_Score
#[6] : strand
#[7] : frac_Watson
#[8] : total
#[9] : unique
#[10] : dicer_call
#[11] : phase_offset
#[12] : phase_pval
#[13] : short
#[14] : long
#[15--end] : dicer size mappings


# output two gff3 files .. one for DCL and the other for NON-DCL loci.
# only do this if a de novo run
unless($count) {
    my ($dcl_file,$nfile) = write_gff3s(\@final_clusters,\%quant_master,\$outdir);
    
    # write gff3 file information to log
    log_it ($logfile,"\nGFF3 files are $dcl_file and $nfile\n");
}

# output the master file
my $big_table = "$outdir" . "\/" . "Results\.txt";
open(BIG, ">$big_table");
print BIG "\#Locus\tName\tFlagOverlap\tSize\tMIRNA\tMIRNA_Score\tStrand\tFrac_Watson\tTotal\tUniques\tDicerCall\tPhaseOffset\tPhase_pval\t";
print BIG "Short\tLong";
for(my $d = $dicermin; $d <= $dicermax; ++$d) {
    print BIG "\t$d";
} 
print BIG "\n";
    
foreach my $f_clus (@final_clusters) {
    print BIG "$quant_master{$f_clus}\n";
}
close BIG;


summarize(\%quant_master,\$nohp,\$dicermin,\$dicermax,\$logfile);

##########################
# If the bamfile had > 1 read group AND no read_group was specified on the command line, assume
#  the user wants to finish up by separatlely quantify EACH of the read groups. Call ShortStack recursively, and 
#  quietly in --count mode

if(%rgs) {
    if((scalar(keys %rgs)) > 1) {
	unless($read_group) {
	    my $rg;
	    log_it($logfile,"\nBeginning count-mode analysis of each read-group separately.\n");
	    my $common_options = "--dicermin $dicermin --dicermax $dicermax --phasesize $phasesize --flag_file $flag_file --minstrandfrac $minstrandfrac --mindicerfrac $mindicerfrac";
	    while(($rg) = each %rgs) {
		log_it($logfile,"\tWorking on read group $rg ... ");
		my $rgoutdir = "$outdir" . "\/" . "rg_$rg";
		system "$0 --outdir $rgoutdir --count $big_table --bamfile $bamfile --read_group $rg $common_options $genome 2> /dev/null";
		log_it($logfile,"Done .. see $rgoutdir\n");
	    }
	}
    }
}

log_it ($logfile,"\nCompleted\n");
log_it ($logfile, `date`);


############### SUB ROUTINE BLOCKS
	
sub usage {
    my($version) = @_;
    my $usage = "\nShortStack version $version

USAGE: ShortStack \[options\] genome.fasta

MODES:
1. Trim, align, and analyze: Requires --reads and --adapter
2. Align, and analyze: Requires --reads
3. Analyze: Requires --bamfile

Type \'ShortStack --help\' for full list of options

DOCUMENTATION: type \'perldoc ShortStack\'
";
    return $usage;
}

sub full_help {
    my($version) = @_;
    my $message = "\nShortStack version $version

USAGE: ShortStack \[options\] genome.fasta

MODES:
1. Trim, align, and analyze: Requires --reads and --adapter
2. Align, and analyze: Requires --reads
3. Analyze: Requires --bamfile

DOCUMENTATION: type \'perldoc ShortStack\'

OPTIONS:
--help : Print a help message and then quit.

--version : Print the version number and then quit.

--outdir [string] : Name of directory to be created to receive results of the run.  Deafults to \"ShortStack_[time]\", where time is \"UNIX time\" (the number of non-leap seconds since Jan 1, 1970 UCT), if not provided

--adapter [string] : Sequence of 3' adapter to search for during adapter trimming. Must be at least 8 nts in length, and all ATGC characters. If provided, reads will be trimmed.

--reads [string] : Path to reads file in fasta (.fa or .fasta extension), fastq (.fastq or .fq extension), or colorspace-fasta (.csfasta extension). Can be multiple files, separated by commas.  ShortStack knows the format only thought the file extensions.

--bowtie_cores [integer] : Number of processor cores to use during bowtie / butter alignment. Default: 1.

--mismatches [integer] : Number of allowable mismatched for butter alignment. Must be 0 or 1. Default: 0.

--max_rep [integer] : Reads with more than this number of possible alignment positions will be reported as unmapped regardless of butter density placement probabilities. Default: 1000.

--ranmax [integer] : Reads with more than this number of possible alignment positions where the choice can't be guided by butter-calculated probabilities will be reported as unmapped. Default: 3.

--HPscore : Minimum maple-derived score in order to keep a locus that failed as a MIRNA as an HP locus. Deafult: 0.8.

--align_only : Exits program after completion of small RNA-seq data alignment, creating BAM file.

--bamfile [string] : Path to properly formatted and sorted BAM alignment file of small RNA-seq data. Files require custom tags provided by the butter aligner.

--read_group [string] : Analyze only the indicated read-group. Read-group must be specified in the bam alignment file header. Default = [not active -- all reads analyzed]

--flag_file [string] : PATH to a simple file of genomic loci of interest.  The ShortStack-analyzed small RNA clusters will be analyzed for overlap with the loci in the flag_file .. if there is any overlap (as little as one nt), it will be reported.  Format for this file is describe below.

--mindepth [integer] : Minimum depth of mapping coverage to define an 'island'.  Default = 20.  Must be at least 2, more than 5 preferred.

--pad [integer] : Number of nucleotides upstream and downstream to extend initial islands during cluster definition.  Default = 100

--dicermin [integer] : Smallest size in the Dicer size range (or size range of interest).  Deafult = 20.  Must be between 15 and 35, and less than or equal to --dicermax

--dicermax [integer] : Largest size in the Dicer size range (or size range of interest).  Deafult = 24.  Must be between 15 and 35, and more than or equal to --dicermin

--miRType [string] : Either \"plant\" or \"animal\".  Defaults to \"plant\". 

--minstrandfrac [float] : Minimum fraction of mappings to one or the other strand call a polarity for non-hairpin clusters.  Also the minimum fraction of \"non-dyad\" mappings to the sense strand within potential hairpins/miRNAs to keep the locus annotated as a hp or miRNA.  See below for details.  Default = 0.8.  Allowed values between 0.5 and 1.

--mindicerfrac [float] : Minimum fraction of mappings within Dicer size range to annotate a locus as Dicer-derived.  Default = 0.85.  Allowed values between 0 and 1.

--phasesize [integer] : Examine phasing only for clusters dominated by the indicated size range.  Size must be within the bounds described by --dicermin and --dicermax.  Set to 'all' to examine p-values of each locus within the Dicer range, in its dominant size.  Set to 'none' to suppress all phasing analysis.  Default = 21.  Allowed values between --dicermin and --dicermax.

--count [string] : Invokes count mode, in which user-provided clusters are annotated and quantified instead of being defined de novo.  When invoked, the file provided with --count is assumed to contain a simple list of clusters.  Count mode also forces nohp mode.  Formatting details below.  Default : Not invoked.

--nohp : If \"--nohp\" appears on the command line, it invokes running in \"no hairpin\" mode.  RNA folding, hairpin annotation, and MIRNA annotation will be skipped (likely saving significant time).  Note that --count mode forces --nohp mode as well.  Default: Not invoked.

";
    return $message;
}

sub merge_clusters {
    my($input,$pad,$genome) = @_; ## passed my reference .. array and scalar
    my @output = ();

    my $this_start;
    my $this_stop;
    my $last_start;
    my $last_stop;
    my $last_padded_start;
    my $last_padded_stop;
    my $this_padded_start;
    my $this_padded_stop;
    my $last_chr = "null";
    my %chr_sizes = ();
    ## grab the chrom sizes, which you need to ensure that you don't pad off the end of the chroms
    # chrom sizes in column 1 from the fai file
    my $fai_file = "$$genome" . "\.fai";
    unless(-e $fai_file) {
	log_it($logfile, "\nFatal in sub-routine get_folding_regions : expected fai file $fai_file does not exist\n");
	exit;
    }
    my @fai_fields = ();
    open(FAI, "$fai_file");

    while (<FAI>) {
	@fai_fields = split ("\t", $_);
	$chr_sizes{$fai_fields[0]} = $fai_fields[1];
    }
    close FAI;
    my $this_chr;
    my $entry;
    foreach my $in_clus (@$input) {
	if($in_clus =~ /^(\S+):(\d+)-(\d+)$/) {
	    $this_chr = $1;
	    $this_start = $2;
	    $this_padded_start = $this_start - $$pad;
	    if($this_padded_start < 1) {
		$this_padded_start = 1;
	    }
	    $this_stop = $3;
	    $this_padded_stop = $this_stop + $$pad;
	    if($this_padded_stop > $chr_sizes{$this_chr}) {
		$this_padded_stop = $chr_sizes{$this_chr};
	    }
	    
	    # special first case
	    if($last_chr eq "null") {
		$last_padded_start = $this_padded_start;
		$last_padded_stop = $this_padded_stop;
		$last_start = $this_start;
		$last_stop = $this_stop;
	    } elsif ($this_chr ne $last_chr) {
		$entry = "$last_chr" . ":" . "$last_start" . "-" . "$last_stop";
		push(@output,$entry);
		$last_padded_start = $this_padded_start;
		$last_padded_stop = $this_padded_stop;
		$last_start = $this_start;
		$last_stop = $this_stop;
	    } else {
		if($this_padded_start > $last_padded_stop) {
		    ## no overlap between these padded clusters.  Report the last one, trimming off its dangling pads
		    $entry = "$this_chr" . ":" . "$last_start" . "-" . "$last_stop";
		    push(@output,$entry);
		    $last_padded_start = $this_padded_start;
		    $last_padded_stop = $this_padded_stop;
		    $last_start = $this_start;
		    $last_stop = $this_stop;
		} else {
		    # here, same chr, this_padded_start is <= last_padded_stop, so we are merging
		    if($this_padded_start < $last_padded_start) {
			$last_padded_start = $this_padded_start;
		    }
		    if($this_start < $last_start) {
			$last_start = $this_start;
		    }
		    if($this_padded_stop > $last_padded_stop) {
			$last_padded_stop = $this_padded_stop;
		    }
		    if($this_stop > $last_stop) {
			$last_stop = $this_stop;
		    }
		}
	    }
	    $last_chr = $this_chr;
	} else {
	    log_it($logfile, "\nFATAL: in sub-routine \'merge_clusters\' : failed to parse initial locus $in_clus\n");
	    exit;
	}
    }
    ## last one
    $entry = "$last_chr" . ":" . "$last_start" . "-" . "$last_stop";
    push(@output,$entry);
    return @output;
}
    

sub get_clusters_a_priori {
    my($flatfile) = @_;
    my @clusters = ();
    my @fields = ();
    my %tracker = ();
    open(FILE, "$flatfile");
    while (<FILE>) {
	chomp;
	# ignore comment lines
	if($_ =~ /^\#/) {
	    next;
	}
	if($_ =~ /\t/) {
	    @fields = split ("\t", $_);
	    unless($fields[0] =~ /^\S+:\d+-\d+$/) {
		log_it($logfile, "\nFATAL in sub-routine get_clusters_a_priori : cluster name $fields[0] is not understandable\n");
		exit;
	    }
	    push(@clusters,$fields[0]);
	    if(exists($tracker{$fields[0]})) {
		log_it($logfile, "\nFATAL in sub-routine get_clusters_a_priori : cluster $fields[0] appears more than once\!  Duplicate loci must be purged prior to analysis\n");
		exit;
	    } else {
		$tracker{$fields[0]} = 1;
	    }
	} else {
	    unless($_ =~ /^\S+:\d+-\d+$/ ) {
		log_it($logfile, "\nFATAL in sub-routine get_clusters_a_priori : cluster name $_ is not understandable\n");
		exit;
	    }
	    if(exists($tracker{$_})) {
		log_it($logfile, "\nFATAL in sub-routine get_clusters_a_priori : cluster $fields[0] appears more than once\!  Duplicate loci must be purged prior to analysis\n");
		exit;
	    } else {
		$tracker{$_} = 1;
	    }
	    push(@clusters,$_);
	}
    }
    close FILE;
    return @clusters;
}

sub get_names_countmode {
    my($flatfile) = @_;
    my %names = ();
    my @fields = ();
    my $n = 0;
    my $entry;
    open(FILE, "$flatfile");
    while (<FILE>) {
	chomp;
	# ignore comment lines
	if($_ =~ /^\#/) {
	    next;
	}
	if($_ =~ /\t/) {
	    @fields = split ("\t", $_);
	    unless($fields[0] =~ /^\S+:\d+-\d+$/) {
		log_it($logfile, "\nFATAL in sub-routine get_names_countmode : cluster name $fields[0] is not understandable\n");
		exit;
	    }
	    if($fields[1]) {
		$names{$fields[0]} = $fields[1];
	    } else {
		log_it($logfile, "\nFATAL in sub-routine get_names_countmode : file is tab-delmited but no name entry in second column\n");
		exit;
	    }
	} else {
	    unless($_ =~ /^\S+:\d+-\d+$/ ) {
		log_it($logfile, "\nFATAL in sub-routine get_names_countmode : cluster name $_ is not understandable\n");
		exit;
	    }
	    ++$n;
	    $entry = "Cluster_" . "$n";
	    $names{$_} = $entry;
	}
    }
    close FILE;
    return %names;
}

sub range_overlap {
    my($q_range,$s_range) = @_;  ## passed by reference .. ranges are arrays, number-number
    my $answer = 0;
    my @q_sorted = sort {$a <=> $b} @$q_range;
    my @s_sorted = sort {$a <=> $b} @$s_range;  ## sorting is necessary to deal with minus-strand hairpins
    my $x;
    # first check .. don't do the time-consuming enumeration if you can easily tell there is no overlap at all.
    if(($q_sorted[1] < $s_sorted[0]) or
       ($s_sorted[1] < $q_sorted[0])) {
	$answer = 0;
    } else {
	for($x = $q_sorted[0]; $x <= $q_sorted[1]; ++$x) {
	    if(($x >= $s_sorted[0]) and
	       ($x <= $s_sorted[1])) {
		$answer = 1;
		last;
	    }
	}
    }
    return $answer;
}

sub range_overlap_count {
    my($q_range,$s_range) = @_;  ## passed by reference .. ranges are arrays, number-number
    my $answer = 0;
    my @q_sorted = sort {$a <=> $b} @$q_range;
    my @s_sorted = sort {$a <=> $b} @$s_range;  ## sorting is necessary to deal with minus-strand hairpins
    my $x;
    for($x = $q_sorted[0]; $x <= $q_sorted[1]; ++$x) {
	if(($x >= $s_sorted[0]) and
	   ($x <= $s_sorted[1])) {
	    ++$answer;
	}
    }
    return $answer;
}
    
sub quant {
    my($clus_array,$bamfile,$dicer_min,$dicer_max,$strand_cutoff,$dicer_cutoff,$phasesize,$names,$read_group) = @_; ## passed by reference .. first one is array, hp_hash and miR_hash are hashes, others scalars
    my %output = ();
    my %internal = ();
    my $total;
    my $watson;
    my $repnorm;
    my $i;
    my @fields = ();
    my $loc_start;
    my $loc_stop;
    my $loc_size;
    my $read_length;
    my $nh;
    my $frac_watson;
    my $frac_crick;
    my $strand;
    my $total_norm;

    my $size_norm;
    
    my %phase_hash = ();
    my $in_dicer_range;
    my $dicer_call;
    my $max_d_size;
    my $max_d_proportion;
    
    my %phase_p_values = ();
    my %phase_offsets = ();
    my $p_val;
    my $offset;    
    
    my $uniques;
    
    #my $ui;
    
    my $x;
    
    # for progress tracking
    my $n_2_analyze = scalar @$clus_array;
    my $five_percent = int($n_2_analyze/20);
    my $n_analyzed = 0;
    log_it($logfile, "\tProgress in sub-routine quant \(dot = five percent\): ");
    
    foreach my $locus (@$clus_array) {
        ## progress
	++$n_analyzed;
	if($n_analyzed >= $five_percent) {
	    ## TEST
	    ##last;
	    ## END TEST
	    log_it($logfile,"\.");
	    $n_analyzed = 0;
	}
	
	%internal = (); ## reset each time
	%phase_hash = (); ## reset each time
	$total = 0;
	$watson = 0;
	$repnorm = 0;
	$uniques = 0;
	$internal{'short'} = 0;
	$internal{'long'} = 0;
	for($i = $$dicer_min; $i <= $$dicer_max; ++$i) {
	    $internal{$i} = 0;
	}
	
	if($locus =~ /:(\d+)-(\d+)/) {
	    $loc_start = $1;
	    $loc_stop = $2;
	    $loc_size = $loc_stop - $loc_start + 1;
	} else {
	    log_it($logfile, "\nFATAL in sub-routine \"quant\" : could not parse coordinates from locus $locus\n");
	    exit;
	}
	# initialize phase hash
	for($i = $loc_start; $i <= $loc_stop; ++$i) {
	    $phase_hash{$i} = 0;
	}
	if($$read_group) {
	    open(SAM, "samtools view -F 0x4 -r $$read_group $$bamfile $locus |");
	} else {
	    open(SAM, "samtools view -F 0x4 $$bamfile $locus |");
	}
	while (<SAM>) {
	    chomp;
	    # ignore header lines, should they be present
	    if($_ =~ /^@/) {
		next;
	    }
	    # get fields
	    @fields = split ("\t", $_);
	    # ignore unmapped reads, should they appear
	    if($fields[1] & 4) {
		next;
	    }
	    $read_length = parse_cigar($fields[5]);

	    # determine the number of total mappings for the read from the XX:i tag
	    $nh = '';
	    if($_ =~ /\tXX:i:(\d+)/) {
		$nh = $1;
	    }
	    unless($nh) {
		log_it($logfile,"\nFATAL in sub-routine \"quant\": Could not parse XX:i flag from sam line $_\n");
		exit;
	    }
	    
	    # tally
	    ++$total;
	    if($nh == 1) {
		++$uniques;
	    }
	    unless($fields[1] & 16) {
		++$watson;
	    }
	    
	    ## $repnorm += (1 / $nh);
	    if($read_length < $$dicer_min) {
		++$internal{'short'};
	    } elsif ($read_length > $$dicer_max) {
		++$internal{'long'};
	    } else {
		++$internal{$read_length};
		## add to phase hash
		## make sure to inlcude reads whose left end is outside the locus.. for those simply add the read length to get a correct register
		if($fields[1] & 16) {
		    if(($fields[3] + 2) < $loc_start) {
			++$phase_hash{($fields[3] + 2 + $read_length)};
		    } else {
			++$phase_hash{($fields[3] + 2)};
		    }
		} else {
		    if($fields[3] < $loc_start) {
			++$phase_hash{($fields[3] + $read_length)};
		    } else {
			++$phase_hash{$fields[3]};
		    }
		}
	    }
	}
	close SAM;
	if($total > 0) {
	    $frac_watson = sprintf ("%.4f", ($watson / $total));
	} else {
	    $frac_watson = 0;
	}
	
	$frac_crick = 1 - $frac_watson;
	
	# Evaluate whether this will be annotated a Dicer-derived locus or not, based on the cutoff supplied
	$in_dicer_range = 0; # reset
	for($i = $$dicer_min; $i <= $$dicer_max; ++$i) {
	    $in_dicer_range += $internal{$i};
	}
	
	if($total > 0) {
	    if(($in_dicer_range / $total) >= $$dicer_cutoff) {
		# is a dicer locus.  find the dicer-read size with max n reads, and calc proportion
		# reset variables
		$max_d_size = "null";
		$max_d_proportion = 0;
		for($i = $$dicer_min; $i <= $$dicer_max; ++$i) {
		    if(($internal{$i} / $total) > $max_d_proportion) {
			$max_d_proportion = $internal{$i} / $total;
			$max_d_size = $i;
		    }
		}
		# shorten the proportion to three decimal places
		$max_d_proportion = sprintf("%.3f",$max_d_proportion);
		## as of version 0.1.2, dicer_call no longer has colon-delimted information, and the proportion is omitted
		#$dicer_call = "$max_d_size" . ":" . "$max_d_proportion"; ## OLD
		$dicer_call = $max_d_size;
	    } else {
		# Not a Dicer locus
		$dicer_call = "N";
	    }
	} else {
	    # shouldn't be here unless somehow $total was zero
	    $dicer_call = "N";
	}
	
	# see whether phasing should be examined
	unless(($$phasesize =~ /^none$/) or
	       ($dicer_call =~ /^N$/)) {
	    if($$phasesize =~  /^all$/) {
		if (($loc_stop - $loc_start + 1) > (4 * $max_d_size)) {
		    ($p_val,$offset) = eval_phasing(\%phase_hash,\$dicer_call,\$loc_start,\$loc_stop);
		    $phase_p_values{$locus} = $p_val;
		    $phase_offsets{$locus} = $offset;
		}
	    } elsif (($dicer_call == $$phasesize) and
		     (($loc_stop - $loc_start + 1) > (4 * $$phasesize))) {
		
		($p_val,$offset) = eval_phasing(\%phase_hash,\$dicer_call,\$loc_start,\$loc_stop);
		$phase_p_values{$locus} = $p_val;
		$phase_offsets{$locus} = $offset;
	    }
	}
	
        # begin entry
	# [0] : locus name
	$output{$locus} .= "$locus";
	
	# [1] : name from name hash
	$output{$locus} .= "\t$$names{$locus}";
	
	# [2] SIZE
	$output{$locus} .= "\t$loc_size";
	
	# [3] : STRAND .. in this sub-routine, based solely upon $$strand_cutoff.
	
	if($frac_watson >= $$strand_cutoff) {
	    $strand = "+";
	} elsif($frac_crick >= $$strand_cutoff) {
	    $strand = "-";
	} else {
	    $strand = "\.";
	}
	$output{$locus} .= "\t$strand";
	
	# [4] FRAC_WAT
	$output{$locus} .= "\t$frac_watson";
	
	# calculate mappings, reporting only in raw in this sub-routine
	# [5] TOTAL
	$output{$locus} .= "\t$total";
	
	# [6] UNIQUE MAPPERS
	$output{$locus} .= "\t$uniques";
	
	# [7] DICER ... either 'N' or a number within the dicer_min to dicer_max range
	# was calculated above
	$output{$locus} .= "\t$dicer_call";
	
	# [8] and [9] .. phase offset and phase p-value
	if(exists($phase_p_values{$locus})) {
	    $output{$locus} .= "\t$phase_offsets{$locus}\t$phase_p_values{$locus}";
	} else {
	    $output{$locus} .= "\tNA\tNA";
	}
		
	# [10] SHORT
	$output{$locus} .= "\t$internal{'short'}";
	
	# [11] LONG
	$output{$locus} .= "\t$internal{'long'}";
	
	# [12] through whenenver .. Dicer 
	for($i = $$dicer_min; $i <= $$dicer_max; ++$i) {
	    $output{$locus} .= "\t$internal{$i}";
	}
    }

    log_it($logfile," Done\n");
    return %output;
}

sub eval_phasing {
    my($phase_hash,$dcall,$loc_start,$loc_stop) = @_; ## passed by reference
    
    my $i;
    my $j;
    
    my $loc_size = ($$loc_stop - $$loc_start + 1);
    my $N;
    my $m;
    my $n;
    my $k;
    
    my $x;
    my $y;
    
    my $term1;
    my $term2;
    my $term2a;
    my $term2b;
    my $denominator;
    
    my $p;

    my $offset;
    
    my $sum = 0;
    
    # determine the phasing size to examine for this locus, which is $i
#    if($$dcall =~ /^(\d+):/) {
#	$i = $1;
#    } else {
#	die "FATAL in sub-routine \'eval_phasing\'  could not parse dicer call $$dcall\n";
#    }
    $i = $$dcall;
    
    # If the locus is larger than 20 * $i, concatenate the phase hash information beyond the first 20 cycles
    my $exam_stop;
    if($loc_size > (20 * $i)) {
	$exam_stop = $$loc_start + (20 * $i) - 1;
	for($x = $$loc_start + (20 * $i); $x <= $$loc_stop; ++$x) {
	    $y = $x;
	    until($y < ($$loc_start + (20 * $i))) {
		$y = $y - (20 * $i);
	    }
	    $$phase_hash{$y} += $$phase_hash{$x};
	}
    } else {
	$exam_stop = $$loc_stop;
    }
    
    # Determine N, the number of all possible states
    $N = $exam_stop - $$loc_start + 1;
    
    
    # determine the mean frequency of occupancy within the exam window
    for($j = $$loc_start; $j <= $exam_stop; ++$j) {
	$sum += $$phase_hash{$j};
    }
    my $mean = $sum / $N;
    
    # count all positions that are above the average within the exam window and also greater than one
    $n = 0;  ## reset
    for($x = $$loc_start; $x <= $exam_stop; ++$x) {
	if(($$phase_hash{$x} > 0) and
	   ($$phase_hash{$x} > $mean)) {
	    ++$n;
	}
    }
    
    # determine the register to examine -- the register with the highest total number of reads
    my $reg_max = 0;
    my $reg_max_offset = 0;
    my $this_total = 0;
    for($j = 0; $j < $i; ++$j) {
	$this_total = 0; ## reset each time	
	for($x = $j + $$loc_start; $x <= $exam_stop; $x += $i) {
	    $this_total += $$phase_hash{$x};
	}
	if($this_total > $reg_max) {
	    $reg_max = $this_total;
	    $reg_max_offset = $j;
	}
    }
    
    # determine m and k in the register of interest within the examination window
    # Use fuzzy phasing, counting -1 and +1 as 'successes' as well as the exact coordinate
    $m = 0; ## reset first
    $k = 0; ## reset first
    # calculate offset
    $offset = $$loc_start + $reg_max_offset;
    for($x = $offset; $x <= $exam_stop; $x += $i) {
	++$m;
	# add flanking nts, as long as they are actually within the window being examined
	if((($x - 1) >= $$loc_start) and
	   (($x - 1) <= $exam_stop)) {
	    ++$m;
	}
	if((($x + 1) >= $$loc_start) and
	   (($x + 1) <= $exam_stop)) {
	    ++$m;
	}
	    
	if(($$phase_hash{$x} > 1) and
	   ($$phase_hash{$x} > $mean)) {
	    ++$k;
	}
	if((($x - 1) >= $$loc_start) and
	   (($x - 1) <= $exam_stop)) {
	    if(($$phase_hash{($x - 1)} > 1) and
	       ($$phase_hash{($x - 1)} > $mean)) {
		++$k;
	    }
	}
	if((($x + 1) >= $$loc_start) and
	   (($x + 1) <= $exam_stop)) {
	    if(($$phase_hash{($x + 1)} > 1) and
	       ($$phase_hash{($x + 1)} > $mean)) {
		++$k;
	    }
	}
    }
    # calculate the p-value
    $p = 0;
    for($y = $k; $y <= $m; ++$y) {
	$term1 = binom_coeff($m,$y);
	$term2a = $N - $m;
	$term2b = $n - $y;
	$term2 = binom_coeff($term2a,$term2b);
	$denominator = binom_coeff($N,$n);
	$p += ($term1 * $term2) / $denominator;
    }
    
    ## TEST
    #print "loc_start: $$loc_start loc_stop: $$loc_stop reg_max: $reg_max reg_max_offset: $reg_max_offset offset: $offset N: $N n: $n m: $m k: $k p: $p\n";
    #print "$i\t$N\t$n\t$m\t$k\t$p\n";
    ## END TEST
    
    # return
    return($p,$offset);
}

sub binom_coeff {
    my($n,$k) = @_; ## thanks PERL monks!
    my $r=1;
    $r*=$n/($n-$k),$n--while$n>$k;
    return $r;
}

sub write_gff3s {
    my($clus_array,$quant_hash,$outdir) = @_; ## passed by reference

    # open files
    my $dclfile = "$$outdir" . "\/" . "$$outdir" . "_DCL.gff3";
    my $nfile = "$$outdir" . "\/" . "$$outdir" . "_N.gff3";
    open(DCL, ">$dclfile");
    open(N, ">$nfile");

    my $i;
    my $j;

    my @fcfields = ();
    my $chrom;
    my $start;
    my $stop;
    my $name;
    foreach my $f_clus (@$clus_array) {
	@fcfields = split("\t",$$quant_hash{$f_clus});
	if($fcfields[0] =~ /^(\S+):(\d+)-(\d+)$/) {
	    $chrom = $1;
	    $start = $2;
	    $stop = $3;
	} else {
	    log_it($logfile, "\nFATAL: in sub-routine \"write_gff3s\" : Could not parse locus name $fcfields[0]\n");
	    exit;
	}
	
	my $out = "$chrom\t" . "ShortStack\t";
	if($fcfields[10] eq "N") {
	    $out .= "NOT_DCL\t";
	} else {
	    $out .= "DCL\t";
	}
	$out .= "$start\t$stop\t\.\t";
	$out .= "$fcfields[6]\t"; ## strand
	$out .= "\.\t";
	$out .= "ID=$fcfields[1]\;";  ## name
	$out .= "Name=$fcfields[1]\;"; ## name
	$out .= "DicerCall=$fcfields[10]\;"; ## DicerCall
	$out .= "HP=";
	if($fcfields[4] eq ".") { ## MIRNA call
	    $out .= "NONE\;";
	} else {
	    $out .= "$fcfields[4]\;"; ## MIRNA call
	}
	$out .= "FracWatson=$fcfields[7]\n";  ## frac watson
	
	if($fcfields[10] eq "N") { ## DicerCall
	    print N "$out";
	} else {
	    print DCL "$out";
	}
    }
    close N;
    close DCL;
    return($dclfile,$nfile);
}
	
sub get_names_simple {
    my($clusters) = @_;
    my %names = ();
    my $n = 0;
    foreach my $loc (@$clusters) {
	++$n;
	$names{$loc} = "Cluster_" . "$n";
    }
    return %names;
}


sub final_summary_nohp {
    my ($clus)  = @_;
    my %hash = ();
    my @fields = ();
    my $size;
    foreach my $line (keys %$clus) {
	@fields = split ("\t", $$clus{$line});
	
	# dicer call
	if($fields[9] eq "N") {  ## array element 9 as of version 0.3.0
	    ++$hash{$fields[9]};
	} else {
	    if($fields[9] =~ /^(\d+)$/) {
		$size = $1;
	    } else {
		log_it($logfile, "\nFATAL in sub-routine final_summary_hp : failed to parse dicer size category of $fields[9]\n");
		exit;
	    }
	    ++$hash{$size};
	}
	
	# phased?
	if($fields[12] =~ /OK/) { ## array element 12 as of version 0.3.0
	    ++$hash{'phased'};
	}
    }
    return %hash;
}

sub final_summary {
    my ($clus)  = @_;
    my %hash = ();
    my @fields = ();
    my $hp_call;
    my $dcall;
    foreach my $line (keys %$clus) {
	@fields = split ("\t", $$clus{$line});
	
	# dicer call
	if($fields[9] eq "N") { ## array element 9 as of version 0.3.0
	    $dcall = $fields[9];
	} else {
	    if($fields[9] =~ /^(\d+)$/) {
		$dcall = $1;
	    } else {
		log_it($logfile, "\nFATAL in sub-routine final_summary_hp : failed to parse dicer size category of $fields[9]\n");
		exit;
	    }
	}
	
	# HP call
	if(($fields[3] eq "MIRNA") or  ## array element 3 as of version 0.3.0
	   ($fields[3] eq "HP")) {
	    $hp_call = "$fields[3]";
	} else {
	    $hp_call = "X";
	}

	++$hash{$dcall}{$hp_call};
	
	# phased?
	if($fields[12] =~ /OK/) {  ## array element 12 as of version 0.3.0
	    ++$hash{'phased'};
	}
    }
    return %hash;
}

sub parse_cigar {
    my($cigar) = @_;
    if($cigar eq "\*") {
	log_it($logfile,"FATAL in sub-routine \'parse_cigar\' : The CIGAR string is missing from at least one of the mappings, so I can't caluclate read length\!\n");
	exit;
    }
    # per the SAM specification, "Sum of lengths of the M/I/S/=/X operations shall equal the length of SEQ."
    my $read_length = 0;
    while($cigar =~ /(\d+)M/g) {
	$read_length += $1;
    }
    while($cigar =~ /(\d+)I/g) {
	$read_length += $1;
    }
    while($cigar =~ /(\d+)S/g) {
	$read_length += $1;
    }
    while($cigar =~ /(\d+)\=/g) {
	$read_length += $1;
    }
    while($cigar =~ /(\d+)X/g) {
	$read_length += $1;
    }
    return $read_length;
}

sub get_colors {
    my($n_to_get) = @_;
    my %rgb_hash = ();
    # initial conditions
    my $r = 255;
    my $g = 0;
    my $b = 0;
    my $x = 1;
    $rgb_hash{$x} = "$r" . "," . "$g" . "," . "$b";
    # increase green
    for(my $i = 1; $i <= 255; ++$i) {
	++$g;
	++$x;
	$rgb_hash{$x} = "$r" . "," . "$g" . "," . "$b";
    }
    # decrease red
    for(my $i = 254; $i >=0; --$i) {
	--$r;
	++$x;
	$rgb_hash{$x} = "$r" . "," . "$g" . "," . "$b";
    }
    # increase blue
    for(my $i = 1; $i <= 255; ++$i) {
	++$b;
	++$x;
	$rgb_hash{$x} = "$r" . "," . "$g" . "," . "$b";
    }
    # decrease green
    for(my $i = 254; $i >=0; --$i) {
	--$g;
	++$x;
	$rgb_hash{$x} = "$r" . "," . "$g" . "," . "$b";
    }
    
    my %answer = ();

    # determine even spacing on the $x number line
    my $denom = $n_to_get - 1;
    if($denom <= 0) {
	$answer{'1'} = $rgb_hash{'1'};
    } else {
	my $spacing = int ($x / $denom);
	my $position = 1;
	$answer{$position} = $rgb_hash{$position};
	for(my $y = 2; $y <= $n_to_get; ++$y) {
	    $position += $spacing;
	    if($position > $x) {
		$position = $x;
	    }
	    $answer{$y} = $rgb_hash{$position};
	}
    }
    
    return %answer;
}
		    
sub get_corrected_strand_frac {
    my($output_string) = @_;
    my @output_lines = split ("\n", $output_string);
    my $sense_mappings = 0;
    my $antisense_mappings = 0;
    my %sense_seqs = ();
    my $real_mappings = 0;
    my $this_seq;
    my $this_n;
    my $revseq;
    foreach my $line (@output_lines) {
	if($line =~ /([AUGC]+).* m=(\d+)/) {
	    $this_seq = $1;
	    $this_n = $2;
	    ++$real_mappings;
	    if($line =~ /</) {
		$revseq = reverse $this_seq;
		if(exists($sense_seqs{$revseq})) {
		    $sense_seqs{$revseq} -= $this_n;
		} else {
		    $antisense_mappings += $this_n;
		}
	    } else {
		$sense_seqs{$this_seq} += $this_n;
	    }
	}
    }
    my $corrected_frac;
    while(($this_seq, $this_n) = each %sense_seqs) {
	$sense_mappings += $this_n;
    }
    my $cor_sum = $sense_mappings + $antisense_mappings;
    if($cor_sum == 0) {
	if($real_mappings > 0) {
	    $corrected_frac = 1;  ## this will occur when all reads are in dyads .. e.g. perfect IR.  we'll keep those!
	} else {
	    $corrected_frac = 0;  ## this is a failsafe in case the sub-routine is passed an entry with no reads at all
	}
    } else {
	$corrected_frac = $sense_mappings / $cor_sum;
    }
    return $corrected_frac;
}
    
sub flag_overlap {
    my($in_hash,$file) = @_; ## passed by reference .. hash and scalar

    my @ss_loci = keys %$in_hash;
    my $s_locus;
    my $s_chr;
    my $s_start;
    my $s_stop;
    my @flag_data = ();
    my $f_string;
    my @f_fields = ();
    my $f_locus;
    my $f_chr;
    my $f_start;
    my $f_stop;
    my $overlap;
    
    my $n_s_overlapped = 0;
    my $n_f_overlapped = 0;
 
    my %f_over = ();

    my @hash_fields = ();
    my @new_hash_fields = ();
    my $hash_value;
    my $x;
    my $new_string;
    
    if(-r $$file) {
	open(FLAG,"$$file");
	@flag_data = <FLAG>;
	close FLAG;
	foreach $s_locus (@ss_loci) {
	    if($s_locus =~ /^(\S+):(\d+)-(\d+)/) {
		$s_chr = $1;
		$s_start = $2;
		$s_stop = $3;
	    } else {
		log_it($logfile, "\nFATAL in sub-routine flag_overlap: failed to parse small RNA locus name $s_locus\n");
		exit;
	    }
	    $overlap = '';
	    foreach $f_string (@flag_data) {
		chomp $f_string;
		@f_fields = split ("\t", $f_string);
		if($f_fields[0] =~ /^(\S+):(\d+)-(\d+)/) {
		    $f_chr = $1;
		    $f_start = $2;
		    $f_stop = $3;
		} else {
		    log_it($logfile, "\nFATAL in sub-routine flag_overlap: failed to parse flag locus name $f_fields[0]\n");
		    exit;
		}
		if($f_chr ne $s_chr) {
		    next;
		} elsif (($s_start > $f_stop) or ($f_start > $s_stop)) {
		    next;
		} else {
		    $f_over{$f_fields[0]} = 1;
		    if($overlap) {
			$overlap .= ",$f_fields[1]";
		    } else {
			$overlap = "$f_fields[1]";
		    }
		}
	    }
	    @hash_fields = split ("\t", $$in_hash{$s_locus});
	    @new_hash_fields = ();
	    $x = 0;
	    foreach $hash_value (@hash_fields) {
		++$x;
		push(@new_hash_fields, $hash_value);
		if($x == 2) {
		    if($overlap) {
			++$n_s_overlapped;
			push(@new_hash_fields, $overlap);
		    } else {
			push(@new_hash_fields, "\.");
		    }
		}
	    }
	    $new_string = join("\t", @new_hash_fields);
	    $$in_hash{$s_locus} = $new_string;
	}
	$n_f_overlapped = scalar (keys %f_over);
	
	# Report to user
	log_it($logfile,"\t\tA total of $n_s_overlapped small RNA loci overlapped with one or more flag_file locus from file $$file\n");
	log_it($logfile,"\t\tA total of $n_f_overlapped loci from flag file $$file overlapped with one or more small RNA locus\n");
    } else {
	# just add a dot to the output hash for all of them
	foreach $s_locus (@ss_loci) {
	    $overlap = "\.";
	    @hash_fields = split ("\t", $$in_hash{$s_locus});
	    @new_hash_fields = ();
	    $x = 0;
	    foreach $hash_value (@hash_fields) {
		++$x;
		push(@new_hash_fields, $hash_value);
		if($x == 2) {
		    push(@new_hash_fields, $overlap);
		}
	    }
	    $new_string = join("\t", @new_hash_fields);
	    $$in_hash{$s_locus} = $new_string;
	}
    }
}

sub summarize {
    my($quant,$nohp,$dicermin,$dicermax,$logfile) = @_;  ## hash, scalar
    my %loci = ();
    my %abun = ();
    my $i;
    
    if($$nohp) {
	$abun{'NA'}{'N'} = 0;
	$loci{'NA'}{'N'} = 0;
	for($i = $$dicermin; $i <= $$dicermax; ++$i) {
	    $abun{'NA'}{$i} = 0;
	    $loci{'NA'}{$i} = 0;
	}
    } else {
	$abun{'MIRNA'}{'N'} = 0;
	$abun{'HP'}{'N'} = 0;
	$abun{'.'}{'N'} = 0;
	$loci{'MIRNA'}{'N'} = 0;
	$loci{'HP'}{'N'} = 0;
	$loci{'.'}{'N'} = 0;
	for($i = $$dicermin; $i <= $$dicermax; ++$i) {
	    $abun{'MIRNA'}{$i} = 0;
	    $abun{'HP'}{$i} = 0;
	    $abun{'.'}{$i} = 0;
	    $loci{'MIRNA'}{$i} = 0;
	    $loci{'HP'}{$i} = 0;
	    $loci{'.'}{$i} = 0;
	}
    }
    
    my @fields = ();
    my $locus;
    my $entry;
    my $rounded;
    
    while(($locus, $entry) = each %$quant) {
	@fields = split ("\t", $entry);
	
	
	# $fields[10] is the Dicer Call
	# $fields[8] is the total number of alignments
	# $fields[4] is the HP call
	++$loci{$fields[4]}{$fields[10]};
	$abun{$fields[4]}{$fields[10]} += $fields[8];
    }
    
    # report
    log_it($$logfile,"\nSummary\n\n");

    if($$nohp) {
	log_it($$logfile,"DicerCall\tLoci\tAlignments\n");
	log_it($$logfile, "N\t$loci{'NA'}{'N'}\t");
	#$rounded = sprintf("%.1f",$abun{'NA'}{'N'});
	log_it($$logfile,"$abun{'NA'}{'N'}\n");
	for($i = $$dicermin; $i <= $$dicermax; ++$i) {
	    log_it($$logfile,"$i\t$loci{'NA'}{$i}\t");
	    #$rounded = sprintf ("%.3f",$abun{'NA'}{$i});
	    log_it($$logfile,"$abun{'NA'}{$i}\n");
	}
    } else {
	log_it($$logfile,"DicerCall\tNON-HP_Loci\tHP_Loci\tMIRNA_Loci\tNON-HP_Alignments\tHP_Alignments\tMIRNA_Alignments\n");
	log_it($$logfile,"N\t$loci{'.'}{'N'}\t$loci{'HP'}{'N'}\t$loci{'MIRNA'}{'N'}\t");
	#$rounded = sprintf("%.1f",$abun{'.'}{'N'});
	log_it($$logfile,"$abun{'.'}{'N'}\t");
	#$rounded = sprintf("%.1f",$abun{'HP'}{'N'});
	log_it($$logfile,"$abun{'HP'}{'N'}\t");
	#$rounded = sprintf("%.1f",$abun{'MIRNA'}{'N'});
	log_it($$logfile,"$abun{'MIRNA'}{'N'}\n");
	for($i = $$dicermin; $i <= $$dicermax; ++$i) {
	    log_it($$logfile,"$i\t$loci{'.'}{$i}\t$loci{'HP'}{$i}\t$loci{'MIRNA'}{$i}\t");
	    #$rounded = sprintf("%.1f",$abun{'.'}{$i});
	    log_it($$logfile,"$abun{'.'}{$i}\t");
	    #$rounded = sprintf("%.1f",$abun{'HP'}{$i});
	    log_it($$logfile,"$abun{'HP'}{$i}\t");
	    #$rounded = sprintf("%.1f",$abun{'MIRNA'}{$i});
	    log_it($$logfile,"$abun{'MIRNA'}{$i}\n");
	}
    }
    log_it($$logfile,"\n");

}

sub log_it {
    my($file,$string) = @_;
    open(LOG, ">>$file");
    print LOG "$string";
    print STDERR "$string";
    close LOG;
}

sub requant {
    my($old_q_string,$bamfile,$dicer_min,$dicer_max,$strand_cutoff,$dicer_cutoff,$phasesize,$read_group,$verdict,$score,$coordinates) = @_;

    # declarations
    my $chr;
    my $start;
    my $stop;
    my %internal = ();
    my $i;
    my %phase_hash = ();
    my @fields = ();
    my $read_length;
    my $nh;
    my $total = 0;
    my $uniques = 0;
    my $watson = 0;
    my $frac_watson;
    my $frac_crick;
    my $in_dicer_range;
    my $max_d_size;
    my $max_d_proportion;
    my $dicer_call;
    my $p_val;
    my $offset;
    my %phase_p_values = ();
    my %phase_offsets = ();
    
    my $out;
    my @old_fields = split ("\t", $old_q_string);
    
    my $size;
    
    # parse coordinates
    if($coordinates =~ /^(\S+):(\d+)-(\d+)$/) {
	$chr = $1;
	$start = $2;
	$stop = $3;
	$size = $stop - $start + 1;
    } else {
	log_it($logfile, "\nFATAL: in sub-routine requant, failed to parse locus $coordinates\n");
	exit;
    }
    
    # initialize holder
    $internal{'short'} = 0;
    $internal{'long'} = 0;
    for($i = $dicer_min; $i <= $dicer_max; ++$i) {
	$internal{$i} = 0;
    }

    # initialize phase hash
    for($i = $start; $i <= $stop; ++$i) {
	$phase_hash{$i} = 0;
    }
    if($read_group) {
	open(SAM, "samtools view -F 0x4 -r $read_group $bamfile $coordinates |");
    } else {
	open(SAM, "samtools view -F 0x4 $bamfile $coordinates |");
    }
    while (<SAM>) {
	chomp;
	# ignore header lines, should they be present
	if($_ =~ /^@/) {
	    next;
	}
	# get fields
	@fields = split ("\t", $_);
	# ignore unmapped reads, should they appear
	if($fields[1] & 4) {
	    next;
	}
	$read_length = parse_cigar($fields[5]);
	
	# determine the number of total mappings for the read from the XX:i tag.
	$nh = '';
	if($_ =~ /\tXX:i:(\d+)/) {
	    $nh = $1;
	}
	
	unless($nh) {
	    log_it($logfile, "\nFATAL in sub-routine \"quant\": Could not parse XX:i flag from sam line $_\n");
	    exit;
	}
	
	# tally
	++$total;
	if($nh == 1) {
	    ++$uniques;
	}
	unless($fields[1] & 16) {
	    ++$watson;
	}
	
	if($read_length < $dicer_min) {
	    ++$internal{'short'};
	} elsif ($read_length > $dicer_max) {
	    ++$internal{'long'};
	} else {
	    ++$internal{$read_length};
	    ## add to phase hash
	    ## make sure to inlcude reads whose left end is outside the locus.. for those simply add the read length to get a correct register
	    if($fields[1] & 16) {
		if(($fields[3] + 2) < $start) {
		    ++$phase_hash{($fields[3] + 2 + $read_length)};
		} else {
		    ++$phase_hash{($fields[3] + 2)};
		}
	    } else {
		if($fields[3] < $start) {
		    ++$phase_hash{($fields[3] + $read_length)};
		} else {
		    ++$phase_hash{$fields[3]};
		}
	    }
	}
    }
    close SAM;
    if($total > 0) {
	$frac_watson = sprintf ("%.4f", ($watson / $total));
    } else {
	$frac_watson = 0;
    }
    
    $frac_crick = 1 - $frac_watson;
    
    # Evaluate whether this will be annotated a Dicer-derived locus or not, based on the cutoff supplied
    $in_dicer_range = 0; # reset
    for($i = $dicer_min; $i <= $dicer_max; ++$i) {
	$in_dicer_range += $internal{$i};
    }
    
    if($total > 0) {
	if(($in_dicer_range / $total) >= $dicer_cutoff) {
	    # is a dicer locus.  find the dicer-read size with max n reads, and calc proportion
	    # reset variables
	    $max_d_size = "null";
	    $max_d_proportion = 0;
	    for($i = $dicer_min; $i <= $dicer_max; ++$i) {
		if(($internal{$i} / $total) > $max_d_proportion) {
		    $max_d_size = $i;
		    $max_d_proportion = $internal{$i} / $total;
		}
	    }
	    $dicer_call = $max_d_size;
	} else {
	    # Not a Dicer locus
	    $dicer_call = "N";
	}
    } else {
	# shouldn't be here unless somehow $total was zero
	$dicer_call = "N";
    }
    
    # see whether phasing should be examined
    unless(($phasesize =~ /^none$/) or
	   ($dicer_call =~ /^N$/)) {
	if($phasesize =~  /^all$/) {
	    if (($stop - $start + 1) > (4 * $max_d_size)) {
		($p_val,$offset) = eval_phasing(\%phase_hash,\$dicer_call,\$start,\$stop);
		$phase_p_values{$coordinates} = $p_val;
		$phase_offsets{$coordinates} = $offset;
	    }
	} elsif (($dicer_call == $phasesize) and
		 (($stop - $start + 1) > (4 * $phasesize))) {
	    
	    ($p_val,$offset) = eval_phasing(\%phase_hash,\$dicer_call,\$start,\$stop);
	    $phase_p_values{$coordinates} = $p_val;
	    $phase_offsets{$coordinates} = $offset;
	}
    }
	    
    # begin entry
    
    # [0] : locus name
    $out = $coordinates;
    
    # [1] : name
    $out .= "\t$old_fields[1]";
    
    # [2] : size
    $out .= "\t$size";

    # [3] : verdict .. MIRNA if PASS, HP if FAIL (had to be either a MIRNA or HP to get to this sub-routine)
    if($verdict eq "PASS") {
	$out .= "\tMIRNA";
    } else {
	$out .= "\tHP";
    }
    
    # [4] : score
    $out .= "\t$score";
    
    # [5] : STRAND
    $out .= "\t$old_fields[3]";
    
    # [6] FRAC_WAT
    $out .= "\t$frac_watson";

    # calculate mappings, reporting only in raw in this sub-routine
    # [7] TOTAL
    $out .= "\t$total";
    
    # [8] UNIQUE MAPPERS
    $out .= "\t$uniques";
	    
    # [9] DICER CALL ... either 'N' or a number within the dicer_min to dicer_max range
    # was calculated above
    $out .= "\t$dicer_call";
	    
    # [10] and [11]: Phase p offset and phase p-value
    if(exists($phase_p_values{$coordinates})) {
	$out .= "\t$phase_offsets{$coordinates}";
	$out .= "\t$phase_p_values{$coordinates}";
    } else {
	$out .= "\tNA\tNA";
    }

    # [12] SHORT
    $out .= "\t$internal{'short'}";
    
    # [13] LONG
    $out .= "\t$internal{'long'}";
	    
    # [14] through whenenver .. Dicer 
    for($i = $dicer_min; $i <= $dicer_max; ++$i) {
	$out .= "\t$internal{$i}";
    }
	
    return $out;
}

sub get_islands {
    my($bamfile,$mindepth,$expected_faidx,$read_group) = @_;
    # go chr by chr, using the .fai index file to get the chr names
    my @chrs = ();
    open(FAI, "$expected_faidx");
    my @fields = ();
    
    my $genome_sum = 0;
    my %fai_hash = ();
    while (<FAI>) {
	chomp;
	@fields = split ("\t", $_);
	push(@chrs, $fields[0]);
	$fai_hash{$fields[0]} = $fields[1];
	$genome_sum += $fields[1];
    }
    close FAI;
    
    my @islands = ();
    
    my $last_start;
    my $ok;
    
    my $started;
    my $stopped;
    my $last_location;
    
    my $island;
    
    my $mindpad;
    
    ## A progress bar based on the % of genome (in nts) analyzed, updated only at the completion of chromosomes
    log_it($logfile,"\tProgress in sub-routine get_islands \(dots = 5 percent\; updates only at completion of a chromosome\): ");
    my $dots_printed = 0;
    my $frac_done = 0;
    my $needed_dots = 0;
    foreach my $chr (@chrs) {
	
	$last_start = -1;
	$ok = '';
	$last_location = -1;
	
	if($read_group) {
	    open(DEPTH, "samtools view -F 0x4 -r $read_group -b -u $bamfile $chr | samtools depth /dev/stdin 2> /dev/null |");
	} else {
	    open(DEPTH, "samtools view -F 0x4 -b -u $bamfile $chr | samtools depth /dev/stdin 2> /dev/null |");
	}
	while (<DEPTH>) {
	    chomp;

	    @fields = split ("\t", $_);
	    if($fields[1] != ($last_location + 1)) {
		if($ok) {
		    # close
		    $island = "$chr" . ":" . "$last_start" . "-" . "$last_location";
		    push(@islands,$island);
		    $ok = '';
		}
		$last_start = $fields[1];
	    }
	    if($fields[2] >= $mindepth) {
		$ok = 1;
	    }
	    $last_location = $fields[1];
	}
	close DEPTH;
	## close the last one, if there is one
	if($ok) {
	    $island = "$chr" . ":" . "$last_start" . "-" . "$last_location";
	    push(@islands,$island);
	}
	
	## update progress bar
	$frac_done += ($fai_hash{$chr} / $genome_sum);
	$needed_dots = int ($frac_done / 0.05);
	until($dots_printed == $needed_dots) {
	    log_it($logfile,"\.");
	    ++$dots_printed;
	}
	
    }
    log_it($logfile," Done\n");
    return @islands;
    
}

sub validate_bam {
    my($bam,$fai) = @_;
    log_it($logfile,"\nValidating bamfile $bam ...");
    my %rg = ();
    $rg{'BAD'} = 1;
    # Is it readable?
    #log_it($logfile, "\tFile readable\? ");
    unless(-r $bam) {
	log_it($logfile, " FAIL: file $bam not readable -- ABORT\n");
	return %rg;
    }
    #log_it($logfile, "YES\n");
    
    # header checks
    my %h_seqs = ();
    #log_it($logfile, "\tHeader present\? ");
    (open(H, "samtools view -H $bam |")) || return %rg;
    my $h;
    my $so;
    my $rgname;
    while (<H>) {
	if($_ =~ /^\@/) {
	    unless($h) {
		$h = 1;
		#log_it($logfile,"YES\n\tSorted by coordinate\? ");
	    }
	    if($_ =~ /^\@HD\t.*SO:(\S+)/) {
		if($1 eq "coordinate") {
		    $so = 1;
		} else {
		    $so = 0;
		}
	    }
	    if($_ =~ /^\@SQ\t.*SN:(\S+)/) {
		$h_seqs{$1} = 1;
	    }
	    if($_ =~ /^\@RG\t.*ID:(\S+)/) {
		$rgname = $1;
		if($_ =~ /DS:(\S+)/) {
		    $rg{$rgname} = $1;
		} else {
		    $rg{$rgname} = "None";
		}
	    }
	}
    }
    close H;
    if($so) {
	#log_it($logfile, "YES\n");
    } else {
	log_it($logfile, " FAIL -- bamfile must be sorted by \'coordinate\' as indicated in the header SO:tag-- ABORT\n");
	return %rg;
    }
    
    # does it match the genome?
    my %fai_names = ();
    #log_it($logfile,"\tMatches genome\? ");
    (open(FAI, "$fai")) || return %rg;
    my @fields = ();
    while (<FAI>) {
	@fields = split ("\t", $_);
	$fai_names{$fields[0]} = 1;
    }
    close FAI;
    my $h_seq;
    while(($h_seq) = each %h_seqs) {
	unless(exists($fai_names{$h_seq})) {
	    log_it($logfile, " FAIL -- reference name $h_seq was not found in genome -- ABORT\n");
	    return %rg;
	}
    }
    #log_it($logfile, "PASS\n");
    
    # Are there read groups defined, and if so, what are they?
    #log_it($logfile,"\tRead Groups\? ");
    if(%rg) {
	#log_it($logfile, "YES. And they are...\n");
	while(($rgname) = each %rg) {
	    unless($rgname eq "BAD") {
		#log_it($logfile,"\t\t$rgname\tDescription: $rg{$rgname}\n");
	    }
	}
    } else {
	#log_it($logfile, "NO\n");
	$rg{'NULL'} = 1;
    }
    
    # Does it have XX, XY, adn XZ tags from butter?  Just check the first line
    #log_it($logfile, "\tHas butter custom tags\? ");
    (open(SAM, "samtools view $bam |")) || return %rg;
    my $check = <SAM>;
    close SAM;
    if (($check =~ /\tXX:i:/) and ($check =~ /\tXY:Z:/) and ($check =~ /\tXZ:f:/)) {
	#log_it($logfile,"PASS\n");
    } else {
	log_it($logfile," FAIL: alignment data appears to lack required butter-derived custom tags. See documentation.\n");
	return %rg;;
    }
    
    ## Is it indexed? If not, index it.
    my $bai = "$bam" . ".bai";
    #log_it($logfile, "\tIndexed file $bai readable\? ");
    if(-r $bai) {
	#log_it($logfile, "YES\n");
    } else {
	#log_it($logfile, "Not yet ... ");
	system "samtools index $bam";
	if(-r $bai) {
	    #log_it($logfile,"Now it does\n");
	} else {
	    log_it($logfile," FAILED to find .bai index and failed to create it with samtools index -- ABORT\n");
	    return %rg;
	}
    }
    
    ## Get the total number of reads
    (open(STAT, "samtools flagstat $bam |")) || return %rg;
    my $n_mapped = 0;
    while (<STAT>) {
	if($_ =~ /^(\d+) \+ \d+ mapped/) {
	    $n_mapped = $1;
	}
    }
    log_it($logfile," PASS\n\tNumber of aligned reads: $n_mapped\n");
    
    delete $rg{'BAD'};
    return %rg;
}


sub check_adapter {
    my($input) = @_;
    my @entries = split (",",$input);
    foreach my $a (@entries) {
	unless($a =~ /^[ACTGactg]{8,}$/) {
	    return 0;
	}
    }
    return 1;
}

sub merge_em {
    my($bamfiles,$outdir) = @_;  ## passed by reference .. array, scalar
    log_it($logfile, "\nMerging initial alignment files...\n");
    
    # Write a header that includes all of the read groups
    # First copy the header of the first bamfile
    
    system "samtools view -H $$bamfiles[0] > ShortStack_SAM_head_temp.txt";
    
    # now add the read groups
    my $out_name = "$$outdir" . ".bam";
    my $command = "samtools merge -r -h ShortStack_SAM_head_temp.txt $out_name";
    my $rg;
    my $bamfile_part;
    foreach $bamfile_part (@$bamfiles) {
	# determine the number of reads
	(open(STAT, "samtools flagstat $bamfile_part |")) || return 0;
	my $n_mapped;
	my $n_all;
	my $n_unmapped;
	while (<STAT>) {
	    if($_ =~ /^(\d+) \+ (\d+) in total/) {
		$n_all = $1 + $2;
	    } elsif ($_ =~ /^(\d+) \+ (\d+) mapped/) {
		$n_mapped = $1 + $2;
	    }
	}
	close STAT;
	$n_unmapped = $n_all - $n_mapped;
	$rg = $bamfile_part;
	$rg =~ s/\.[^\/]+$//g;   #### s/\..*$//g;  bug-fix 1.2.4
	log_it($logfile, "\tRead Group: $rg added to list .. Mapped: $n_mapped Unmapped: $n_unmapped\n");
	# add to header
	system "echo \"\@RG\tID:$rg\tDS:Mapped=$n_mapped\;Unmapped=$n_unmapped\" >> ShortStack_SAM_head_temp.txt";
	# add to command
	$command .= " $bamfile_part";
    }
    
    # Call the merger
    system "$command";
    
    # check success
    unless(-r $out_name) {
	log_it($logfile, "\nFATAL: merge of initial alignments failed\n");
	exit;
    }
    
    # clean up by deleting the component bam files and the temp header file
    foreach $bamfile_part (@$bamfiles) {
	system "rm -f $bamfile_part";
    }
    system "rm -f ShortStack_SAM_head_temp.txt";
    
    # log it
    log_it($logfile,"\n\tCompleted merge of alignments. Final file is $out_name\n");
    
    return $out_name;
}


sub install_check {
    my($program) = @_; 
    (open(CHECK, "which $program |")) || return 0;
    my $response = <CHECK>;
    chomp $response;
    return $response;
}

	       

__END__

=head1 LICENSE

ShortStack

Copyright (C) 2012-2014 Michael J. Axtell                                                             
                                                                                                 
This program is free software: you can redistribute it and/or modify                             
it under the terms of the GNU General Public License as published by                             
the Free Software Foundation, either version 3 of the License, or                                
(at your option) any later version.                                                              
                                                                                                 
This program is distributed in the hope that it will be useful,                                  
    but WITHOUT ANY WARRANTY; without even the implied warranty of                                   
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the                                    
GNU General Public License for more details.                                                     
                                                                                                 
You should have received a copy of the GNU General Public License                                
along with this program.  If not, see <http://www.gnu.org/licenses/>.

=head1 SYNOPSIS

Annotation and quantification of small RNA genes based upon reference-aligned small RNA sequences

=head1 CITATION

If you use ShortStack in your work, please cite 

Axtell MJ. (2013) ShortStack: Comprehensive annotation and quantification of small RNA genes.  RNA 19:740-751. doi:10.1261/rna.035279.112

Shahid S., Axtell MJ. (2013) Identification and annotation of small RNA genes using ShortStack. Methods doi:10.1016/j.ymeth.2013.10.004

=head1 AUTHOR

Michael J. Axtell, Penn State University, mja18@psu.edu

=head1 DEPENDENCIES

perl
samtools
RNAfold
butter
bowtie
bowtie-build
maple

ShortStack is a perl5 script, so it needs perl5 to compile. It expects to find perl5 at /usr/bin/perl. If this is not where your perl is, modify line 1 of ShortStack (the hashbang) accordingly. It also requires the package Getopt::Long, which I think is standard in most Perl distributions. If this package is not installed, get it from CPAN.

samtools <http://samtools.sourceforge.net/> needs to be installed in your PATH. ShortStack was developed using samtools 0.1.18. Other versions should be OK as far as I know, but let me know if not!

RNAfold is from the ViennaRNA package. See <http://www.tbi.univie.ac.at/~ronny/RNA/vrna2.html>. Both need to be installed in your PATH.

butter (bowtie using iterative placement of repetitive small RNAs) ships with ShortStack, and is also at http://github.com/MikeAxtell/butter . It must be installed in your PATH.

bowtie and bowtie-build must be version "1" .. either 0.12.x or 1.x.  These are required ONLY if you are aligning reads to the genome. Bowtie can be found at http://bowtie-bio.sourceforge.net/index.shtml. Like the other dependencies, they must be in your PATH.

maple (microRNA analysis program leveraging expression) ships with ShortStack, and is also at http://github.com/MikeAxtell/maple . It must be installed in your PATH.

=head1 INSTALL

There is no 'real' installation. After installing the dependencies (see above), you should check to make sure the ShortStack is executable. It should be, but if not you can:                                                                
                                                                                                 
    chmod +x ShortStack
                                                                                                 
Then add it to your PATH .. for instance

sudo cp ShortStack /usr/bin/


=head1 USAGE
                                                                                                                             
ShortStack [options] [genome.fasta] 

There are three modes which differ in the the types of pre-analysis that are performed. Each of the modes has a different set of REQUIRED options:

Mode 1: Trim small RNA-seq reads to remove 3' adapter seqeuence, align them, and then analyze.  Required options:

--reads

--adapter

Mode 2: Align pre-trimmed small RNA-seq reads, and then analyze. Required option:

--reads

Mode 3: Analyze a pre-existing BAM alignment of small RNA-seq reads. Required option:

--bamfile

Additionally, in modes 1 or 2, the option --align_only will terminate analysis after making the alignment file.

=head1 OPTIONS

--help : Print a help message and then quit.

--version : Print the version number and then quit.

--outdir [string] : Name of directory to be created to receive results of the run.  Deafults to \"ShortStack_[time]\", where time is \"UNIX time\" (the number of non-leap seconds since Jan 1, 1970 UCT), if not provided

--adapter [string] : Sequence of 3' adapter to search for during adapter trimming. Must be at least 8 nts in length, and all ATGC characters. If provided, reads will be trimmed.

--reads [string] : Path to reads file in fasta (.fa or .fasta extension), fastq (.fastq or .fq extension), or colorspace-fasta (.csfasta extension). Can be multiple files, separated by commas.  ShortStack knows the format only thought the file extensions.

--bowtie_cores [integer] : Number of processor cores to use during bowtie / butter alignment. Default: 1.

--mismatches [integer] : Number of allowable mismatched for butter alignment. Must be 0 or 1. Default: 0.

--max_rep [integer] : Reads with more than this number of possible alignment positions will be reported as unmapped regardless of butter density placement probabilities. Default: 1000.

--ranmax [integer] : Reads with more than this number of possible alignment positions where the choice can't be guided by butter-calculated probabilities will be reported as unmapped. Default: 3.

--HPscore : Minimum maple-derived score in order to keep a locus that failed as a MIRNA as an HP locus. Deafult: 0.8.

--align_only : Exits program after completion of small RNA-seq data alignment, creating BAM file.

--bamfile [string] : Path to properly formatted and sorted BAM alignment file of small RNA-seq data. Files require custom tags provided by the butter aligner.

--read_group [string] : Analyze only the indicated read-group. Read-group must be specified in the bam alignment file header. Default = [not active -- all reads analyzed]

--flag_file [string] : PATH to a simple file of genomic loci of interest.  The ShortStack-analyzed small RNA clusters will be analyzed for overlap with the loci in the flag_file .. if there is any overlap (as little as one nt), it will be reported.  Format for this file is describe below.

--mindepth [integer] : Minimum depth of mapping coverage to define an 'island'.  Default = 20.  Must be at least 2, more than 5 preferred.

--pad [integer] : Number of nucleotides upstream and downstream to extend initial islands during cluster definition.  Default = 100

--dicermin [integer] : Smallest size in the Dicer size range (or size range of interest).  Deafult = 20.  Must be between 15 and 35, and less than or equal to --dicermax

--dicermax [integer] : Largest size in the Dicer size range (or size range of interest).  Deafult = 24.  Must be between 15 and 35, and more than or equal to --dicermin

--miRType [string] : Either \"plant\" or \"animal\".  Defaults to \"plant\". 

--minstrandfrac [float] : Minimum fraction of mappings to one or the other strand call a polarity for non-hairpin clusters.  Also the minimum fraction of \"non-dyad\" mappings to the sense strand within potential hairpins/miRNAs to keep the locus annotated as a hp or miRNA.  See below for details.  Default = 0.8.  Allowed values between 0.5 and 1.

--mindicerfrac [float] : Minimum fraction of mappings within Dicer size range to annotate a locus as Dicer-derived.  Default = 0.85.  Allowed values between 0 and 1.

--phasesize [integer] : Examine phasing only for clusters dominated by the indicated size range.  Size must be within the bounds described by --dicermin and --dicermax.  Set to 'all' to examine p-values of each locus within the Dicer range, in its dominant size.  Set to 'none' to suppress all phasing analysis.  Default = 21.  Allowed values between --dicermin and --dicermax.

--count [string] : Invokes count mode, in which user-provided clusters are annotated and quantified instead of being defined de novo.  When invoked, the file provided with --count is assumed to contain a simple list of clusters.  Count mode also forces nohp mode.  Formatting details below.  Default : Not invoked.

--nohp : If \"--nohp\" appears on the command line, it invokes running in \"no hairpin\" mode.  RNA folding, hairpin annotation, and MIRNA annotation will be skipped (likely saving significant time).  Note that --count mode forces --nohp mode as well.  Default: Not invoked.

=head1 KEY FORMATTING REQUIREMENTS AND ASSUMPTIONS

=head2 Input genome.fasta file

It is critical that this be the precise genome to which the reads in the input .bam file were mapped. If it isn't, validation of the BAM alignment file will fail and the run will be aborted.

Chromsome names that contain whitespace will be truncated; only the first string of non-white-space characters will be maintained. This applies both during alignment (where bowtie does this) and during the rest of the analysis (where samtools does this, when creating the .fai index file).

If not already present, a .fai index file for the genome will be created using samtools faidx at the beginning of the run. As above, chromosome names will be automatically trimmed starting at the first white-space character, if present.

=head2 Small RNA-seq reads.

FASTA or FASTQ data should be devoid of comment lines and conform to FASTA or FASTQ specs. In addition, ShortStack assumes that each read will occupy a single line in the file. There is no support for paired-end reads.  Colorspace-FASTA formatted data (from SOLiD) can have comment lines. Format is assumed to conform to colorspace-FASTA specifications (beginning with a nucleotide, followed by a string of colors [0,1,2,3] or ambiguity codes [.].  For SOLiD data, the quality values (_QV.qual files) are not usable as valid inputs.

=head2 Input .bam file

As of ShortStack 2.0.0, bam alignment files must have been created with the program butter. Validation of bam files requires:

If you do make your own BAM alignments, outside of ShortStack, they must pass the following validation steps that are performed by ShortStack:

1. The header must be present

2. The sort order of the file must be 'coordinate', as indicated by the SO: tag in the header

3. All of the chromosome names found in the header MUST also be found in the genome.fasta file

4. The data lines must contain the custom XX, XY, and XZ tags added by butter.

5. If the option --read_group is being used, the specified read_group must be mentioned in the header in an @RG line.

The BAM file should be indexed and have the corresonding .bam.bai index file in the same path as the bamfile. However, this is not required to pass validation .. if the index is not found, it will be created during the run.

Each mapped read must have the CIGAR string set (column 6 in the SAM specification) -- ShortStack determines the small RNA lengths by parsing the CIGAR string .. if any mappings (except unmapped reads, which are ignored) have "*" entered instead of a valid CIGAR string ShortStack will exit and complain.

=head2 --count file

If running in --count mode, the user-provided file is expected to be a simple text file containing a list of coordinates in the format : [Chr]:[start]-[stop], where Chr is defined in the genome file AND in the .bam file, and start and stop are one-based, inclusive.  The same requirement for short, non-whitespaced chromosome names as discussed above holds true for input --count files.  Comment lines, that begin with '#', are ignored.  Tab-delimited files are also accepted, provided the first column has the coordinates.  The second column in tab-delimted files is assumed to be the names of the clusters, and will be used accordingly.  Any other columns in a tab-delimited input file are ignored.

Importantly, the 'Results.txt' file produced by a previous ShortStack run can be used directly in subsequent runs in --count mode.  This is useful when comparing identical intervals across multiple samples.

Note that count mode also forces nohp mode.

=head2 --flag_file

Optional.  This is a list of genomic loci to scan for overlap with one or more of the small RNA loci found/analyzed by ShortStack.  Overlap of any length is reported.  The format of the file is similar to that of the --count file:  A tab-delimited text file with coordinates in the first column, and names in the second column.  Unlike for --count files, names are required to be present in the second column for --flag_file.  Coordinates must be in the format [Chr]:[start]-[stop], where Chr is defined in the genome file AND the .bam file, and start and stop are one-based, inclusive.

=head1 OUTPUT

=head2 Results.txt

This is a simple tab-delimited text file.  The first line begins with a "#" (comment) sign, and then lists column headers.  Each subsequent line describes the key traits of a single cluster.

To import this into R, here's a tip to deal with the first line, which has the headers but begins with a "#" character.

    >results <- read.table("Results.txt", head=TRUE, sep="\t", comment.char="")

Column 1: Locus : The genome-browser-friendly coordinates of the clusters.  Coordinates are one-based, inclusive (e.g. Chr1:1-100 refers to a 100 nt interval beginning with nt 1 and ending with nt 100).

Column 2: Name : Name of cluster.  Unless the run was in --count mode and the input file of a priori clusters already had names, the names are arbitrarily designated as "Cluster_1", "Cluster_2", etc.

Column 3: FlagOverlap : Name(s) of any loci from the flag_file that overlap with the cluster are listed.  If there are two or more, they are comma-separated.  If there were none, or no flag_file was provided, than a "." is present in this column instead.

Column 4: Size : Size in nts of the locus.

Column 5: MIRNA : Whether this cluster appears to be a MIRNA or not.  If not, a "." is present.  If it is a hairpin, but NOT qualified as a MIRNA, "HP" is indicated.  MIRNAs are indicated by "MIRNA".  If the run was in "--nohp" mode, than all entries in the column will be ".".

Column 6: MIRNA_Score : Score of the locus via MIRNA analysis by maple. Ranges from 0-1, with 1 being the best. "NA" if locus was pre-excluded from maple analysis (because of excessive length, not coming from a clear single-strand, or DicerCall of N).

Column 7: Strand : The predominant genomic strand from which the small RNA emanate.  If ".", no strand was called.

Column 8: Frac_Wat : Fraction of aligned reads to the Watson (e.g. +) strand of the cluster.  1 means all were from Watson Strand (e.g. +), 0 means all were from Crick (e.g. -) strand.

Column 9: Total : Total aligned reads within the cluster.

Column 10: Uniques : Total aligned reads derived from uniquely mapped reads .. e.g., those with XX:i:1.

Column 11: DicerCall : If "N", the cluster was not annotated as dicer-derived, per options --dicermin, --dicermax, and --mindicerfrac.  Otherwise this is a number, within the --dicermin to --dicermax size range, which indicates the most abundant small RNA size within the mappings at that cluster.

Column 12: PhaseOffset : If "NA", phasing p-value was not calculated for this cluster.  Otherwise, the offset is the one-based genomic position with which the cluster appears to be "in-phase" (based on the 5' nt of a sense-mapped small RNA).  Phasing is always in increments identicial to the Dicer size call in column 9.

Column 13: Phase_pval :  If "NA", phasing p-value was not calculated for this cluster.  Otherwise, the p-value is derived from a modified hypergeometric distribution, as described below. 

Column 14: Short : The total mappings from reads with lengths less than --dicermin.

Column 15: Long : The total mappings from reads with lengths more than --dicermax.

Columns 16 - the end : The total mappings from reads with the indicated lengths.  These are the sizes within the Dicer range.

=head2 Log.txt

This is a simple log file which records the information that is also sent to STDERR during the run.

=head2 gff3 files

Two gff3-formatted files are created, one for the 'DCL' loci (those with a DicerCall that is NOT N), and the 'N' loci (those with a DicerCall of 'N'). There are NOT produced in a --count mode run.

=head2 Hairpin and MIRNA detail files

Text-based and graphical files for each MIRNA and HP locus are created. See the maple documentation for details.

=head1 KEY METHODS

=head2 Adapter trimming and alignments

Adapter trimming and alignments are handled by butter. See the butter documentation for details.

=head2 Multiple libraries

ShortStack supports input of multiple small RNA-seq libraries through the option --reads. Files are provided as a comma-delimited list. When multiple small RNA-seq libraries are input, each one is first aligned separately, creating temporary .bam files. When this is complete, they are merged into a single alignment, which is given the name "outdir.bam" in the working directory, where "outdir" is the string given in option --outdir. During the merging, the read group information is stored, so all alignments can be de-convoluted back to their parent libraries if desired. The individual .bam alignments created intially are deleted.

=head2 Read groups

As of version 1.1.0, ShortStack incorporates the option --read_group. When specified, only the alignments from the read group specified by the option will be used for analysis. Use of this option demands that the indicated read group is specified in the header of the relevant bam alignment file.

When an analysis uses a bam alignment file that contains more than one read group (based on the bam header), and the --read_group option was NOT used in the run, the analysis will conclude with a --count mode analysis of each read group separately. This is meant to be convenient for analyses in which a de-novo small RNA gene annotation is performed using a merger of multiple libraries, followed by quantification of each locus for each small RNA-seq library separately .. this should facilitate the downstream analysis of differential expression, for instance.

=head2 de novo Cluster Discovery

Cluster discovery proceeds in two simple steps:

1. The total depth of small RNA coverage at each occupied nucleotide in the genome is examined, and initial 'islands' of coverage are defined as continuous stretches of non-zero coverage where the read depth, at at lest one point, is greater than or equal to the threshold depth specified by option --mindepth.  Note that this definition of islands is different, and more inclusive, than that used by ShortStack versions prior to 2.0.0.

2. The initial islands are then temporarily extended on both sides by the distance specified by option --pad.  Islands that overlap after extension are merged.  The "dangling pads" at the ends of the merged clusters are then removed.  After all extensions, resultant mergers, and end trimmings are performed, the final result is the initial clusters.  If the run is performed in --nohp mode, these are the final clusters.  If hairpins and MIRNAs are being examined, some of the clusters may be adjusted in position to reflect the extent of the apparent hairpin precursor.

=head2 Hairpin and MIRNA analysis

MIRNA analysis is performed by maple. For speed, not all clusters are subject to analysis by maple. Clusters that exceed 1kb in length, have a DicerCall of "N", or that don't have a clear single-stranded pattern of read alignments are not sent to maple for analysis. The miRType option also limits queries based on kingdonm-specific requirement (specifically, if the miRTtype is 'animal', than the query can't be longer than 250 nts.).

See the maple documentation for details of how it works.

=head2 Quantification of clusters

All mappings with at lease one nt of overlap within the cluster are tallied as being within the cluster.  Thus, for a cluster located at Chr1:1000-2000, reads mapped to 980-1000, 1100-1123, and 2000-2021 are all counted as being within the cluster during quantification.  Note that it's possible to count the same mapping within non-overlapping clusters.

=head2 Analysis of Phasing

'Phasing' describes the periodic mapping of small RNAs to repeating intervals equal to their size.  It occurs when helical RNA is Diced processively from a defined terminus; often the terminus is defined by a prior small RNA slicing event followed by RDRP activity, although some MIRNA hairpins are also phased.  Nearly all documented examples of phased small RNA production (in plants) occur for 21nt small RNAs in 21nt increments, hence the default settings of ShortStack to examine only 21-dominated clusters.  This can be changed with option --phasesize.

ShortStack's basic method to identify phased small RNAs involves calculation of a p-value based on the hypergeometric distribution -- this approach was inspired by Chen et al. (2007) PNAS 104: 3318-3323 PMID: 17360645.  However, ShortStack's method modifies the Chen et al. approach to make it more robust at detecting phasing in highly expressed clusters with a background of non-phased noise; the method also allows phasing analysis in any register within the dicer size range (controlled by option --phasesize), and analyzes regions of arbitrary length.  Finally, ShortStack's analysis of phasing is "fuzzy" -- that it, exactly phased reads, and those +1 and -1 phase are all counted as "phased".

Phasing analysis proceeds as follows:

1. Clusters to be analyzed must be annotated as Dicer-derived and be dominated by the size class indicated by option --phasesize.  If --phasesize is set to 'all', all clusters within the Dicer size range will be analyzed.  Conversely, phasing analysis is suppressed for all clusters if option --phasesize is set to 'none'.

2. Cluster must also have a length of more than 4 x the phase size in question .. so, more than 84nts under the default --phasesize 21 setting.  Clusters that are too short are never examined.

3. Phasing is only analyzed with respect to the dominant size of the cluster.  So, for a cluster dominated by 21mers, only phasing in 21nt increments will be examined.

4. The 5' positions of all sense-mapped small RNAs are tallied as a function of genomic position.  The 3' positions of all antisense-mapped small RNAs are also tallied, after adding 2nts to account for the 2nt, 3' overhangs left by Dicer processing.  After this process, each genomic position within the cluster has a number reflecting the number of small RNA termini at that position.  If the cluster is longer than 20 times the phase (e.g. 20 x 21 for the default settings), reads mapped beyond the 20 x 21 mark are allocated to the beginning of the cluster, keeping it in phase.  For instance, assuming --phasesize of 21, reads in position 420 are assigned at 420, those at 421 get flipped back to 1, 422 back to 2, and so on.  This is necessary because p-value calculation involved calculation of binomial coefficents, which grow too large to calculate (easily) with inputs of more than 500 or so.

5. The average abundance of termini across the locus is calculated from the above representation of the reads.

6. The total abundance in each of the possible phasing registers (there are 21 registers in the default mode of --phasesize 21) is calculated.  The register with the maximum total abundance is the used in p-value determination.  The offset of this register is also noted; the offset is the 1st genomic position representing the 5'-sense position of a phased small RNA.

7.  The p-value within the chosen register is then calculated using the cumulative distribution function (CDF) for the hypergeometric distribution.  Sorry, hard to show equations in plain-text -- see Wikipedia's Hypergeometric distribution entry, under CDF. N (the population size) is the number of nt positions in the locus. m (the number of success states in the population) is the number of possible positions in the phasing register of interest, INLCUDING POSITIONS +1 AND -1 RELATIVE TO THE REGISTER OF INTEREST.  This means phasing is "fuzzy", which is often seen in the known examples of this phenomenon.  n (the number of draws) is defined as the total number of positions with ABOVE AVERAGE abundance.  k (the number of successes) is the number of phased positions (inlduing the fuzzy +1 and -1 positions) with ABOVE AVERAGE abundance.  The p-value is then calculated per the hypergeometric distribution CDF.  NOTE: The restriction of n and k to only above-average abundance works well to eliminate low-level noise and focus on the dominant small RNA pattern within the locus.

Note: P-values are not corrected for multiple-testing.  Consider adjustment of p-values to control for multiple testing (e.g. Bonferroni, Benjamini-Hochberg FDR, etc) if you want a defensible set of phased loci from a genome-wide analysis.

=cut


